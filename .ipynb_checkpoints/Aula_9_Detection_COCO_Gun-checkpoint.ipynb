{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='background-color: #f0f8ff; border: 3px solid Blue;'>\n",
        "    <font size=\"+1\" color=\"Blue\">\n",
        "        <b>ðŸš€ Transfer Learning - Faster R-CNN para DetecÃ§Ã£o de Armas</b>\n",
        "    </font>\n",
        "</div>\n",
        "<div style='background-color: #fff7f7; border: 2px solid Green;'>\n",
        "    <font size=\"+1\" color=\"Green\">\n",
        "        <b>âœ… Baseado em Aula_9_Detection - Adaptado para Dataset COCO</b>\n",
        "    </font>\n",
        "</div>\n",
        "<div style='background-color: #fffacd; border: 2px solid Orange;'>\n",
        "    <font size=\"+1\" color=\"Orange\">\n",
        "        <b>ðŸ“¦ Dataset: 5% do dataset_final_coco - Apenas classe \"Gun\"</b>\n",
        "    </font>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instala dependÃªncias necessÃ¡rias\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "def install_package(package):\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--upgrade\", \"-q\"])\n",
        "        print(f\"âœ… {package} instalado!\")\n",
        "        return True\n",
        "    except:\n",
        "        print(f\"âŒ Erro ao instalar {package}\")\n",
        "        return False\n",
        "\n",
        "print(\"ðŸ“¦ Instalando dependÃªncias...\")\n",
        "install_package(\"pycocotools\")\n",
        "install_package(\"albumentations\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision import transforms\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from torch.utils.data import Dataset, Subset\n",
        "import random\n",
        "\n",
        "# Verifica GPU\n",
        "print(\"\\nðŸ” Verificando GPU...\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"âœ… GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"âš ï¸  GPU nÃ£o disponÃ­vel - usando CPU\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Define diretÃ³rios\n",
        "BASE_DIR = os.getcwd()\n",
        "DATASET_DIR = os.path.join(BASE_DIR, \"dataset_final_coco\")\n",
        "root_dir = DATASET_DIR\n",
        "\n",
        "print(f\"\\nðŸ“ DiretÃ³rio base: {BASE_DIR}\")\n",
        "print(f\"ðŸ“ Dataset: {DATASET_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# DATASET COCO - Adaptado do FASTER R-CNN.ipynb\n",
        "# ================================================================\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "def get_train_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Resize(height=640, width=640, p=1.0),\n",
        "            A.Normalize(\n",
        "                mean=(0.485, 0.456, 0.406),\n",
        "                std=(0.229, 0.224, 0.225),\n",
        "                max_pixel_value=255.0\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ],\n",
        "        bbox_params=A.BboxParams(\n",
        "            format=\"pascal_voc\",\n",
        "            label_fields=[\"labels\"],\n",
        "            min_visibility=0.0\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_eval_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Resize(height=640, width=640, p=1.0),\n",
        "            A.Normalize(\n",
        "                mean=(0.485, 0.456, 0.406),\n",
        "                std=(0.229, 0.224, 0.225),\n",
        "                max_pixel_value=255.0\n",
        "            ),\n",
        "            ToTensorV2()\n",
        "        ],\n",
        "        bbox_params=A.BboxParams(\n",
        "            format=\"pascal_voc\",\n",
        "            label_fields=[\"labels\"],\n",
        "            min_visibility=0.0\n",
        "        )\n",
        "    )\n",
        "\n",
        "class CocoAlbumentationsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, img_dir, ann_file, transforms=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        with open(ann_file, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        self.images = {img[\"id\"]: img for img in data[\"images\"]}\n",
        "        self.annotations = {}\n",
        "        for ann in data[\"annotations\"]:\n",
        "            img_id = ann[\"image_id\"]\n",
        "            if img_id not in self.annotations:\n",
        "                self.annotations[img_id] = []\n",
        "            self.annotations[img_id].append(ann)\n",
        "\n",
        "        self.ids = list(self.images.keys())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.ids[idx]\n",
        "        info = self.images[img_id]\n",
        "\n",
        "        img_path = os.path.join(self.img_dir, info[\"file_name\"])\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "\n",
        "        annots = self.annotations.get(img_id, [])\n",
        "\n",
        "        if len(annots) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for ann in annots:\n",
        "            x, y, w, h = ann[\"bbox\"]\n",
        "            boxes.append([x, y, x + w, y + h])\n",
        "            labels.append(ann[\"category_id\"])  # category_id=1 para Gun\n",
        "\n",
        "        if self.transforms:\n",
        "            transformed = self.transforms(\n",
        "                image=image,\n",
        "                bboxes=boxes,\n",
        "                labels=labels\n",
        "            )\n",
        "            image = transformed[\"image\"]\n",
        "            boxes = transformed[\"bboxes\"]\n",
        "            labels = transformed[\"labels\"]\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            return None\n",
        "\n",
        "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": boxes,\n",
        "            \"labels\": labels,\n",
        "            \"image_id\": torch.tensor([img_id], dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        return image, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    return tuple(zip(*batch))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# CRIAR DATASETS COM 5% DOS DADOS\n",
        "# ================================================================\n",
        "\n",
        "print(\"ðŸ“¦ Criando datasets...\")\n",
        "\n",
        "train_dataset_full = CocoAlbumentationsDataset(\n",
        "    f\"{root_dir}/train/images\",\n",
        "    f\"{root_dir}/coco_annotations_train.json\",\n",
        "    transforms=get_train_transforms()\n",
        ")\n",
        "\n",
        "val_dataset_full = CocoAlbumentationsDataset(\n",
        "    f\"{root_dir}/val/images\",\n",
        "    f\"{root_dir}/coco_annotations_val.json\",\n",
        "    transforms=get_eval_transforms()\n",
        ")\n",
        "\n",
        "test_dataset = CocoAlbumentationsDataset(\n",
        "    f\"{root_dir}/test/images\",\n",
        "    f\"{root_dir}/coco_annotations_test.json\",\n",
        "    transforms=get_eval_transforms()\n",
        ")\n",
        "\n",
        "# Usar apenas 5% dos dados\n",
        "TRAIN_SUBSET_PERCENT = 0.05\n",
        "VAL_SUBSET_PERCENT = 0.05\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "train_size = int(len(train_dataset_full) * TRAIN_SUBSET_PERCENT)\n",
        "val_size = int(len(val_dataset_full) * VAL_SUBSET_PERCENT)\n",
        "\n",
        "train_indices = random.sample(range(len(train_dataset_full)), train_size)\n",
        "val_indices = random.sample(range(len(val_dataset_full)), val_size)\n",
        "\n",
        "train_dataset = Subset(train_dataset_full, train_indices)\n",
        "val_dataset = Subset(val_dataset_full, val_indices)\n",
        "\n",
        "print(f\"\\nâœ… Datasets criados:\")\n",
        "print(f\"   ðŸ“Š Treino: {len(train_dataset)} imagens ({TRAIN_SUBSET_PERCENT*100:.0f}%)\")\n",
        "print(f\"   ðŸ“Š ValidaÃ§Ã£o: {len(val_dataset)} imagens ({VAL_SUBSET_PERCENT*100:.0f}%)\")\n",
        "print(f\"   ðŸ“Š Teste: {len(test_dataset)} imagens\")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# MODELO - TRANSFER LEARNING (Baseado em Aula_9_Detection)\n",
        "# ================================================================\n",
        "\n",
        "print(\"ðŸ”§ Configurando modelo com Transfer Learning...\")\n",
        "\n",
        "# Carregar modelo prÃ©-treinado no COCO\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "# Substituir o classificador para nossa classe (background + gun)\n",
        "num_classes = 2  # background + gun\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"âœ… Modelo configurado!\")\n",
        "print(f\"   ðŸ“Š Classes: {num_classes} (background + gun)\")\n",
        "print(f\"   ðŸ“Š Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# OTIMIZADOR E SCHEDULER\n",
        "# ================================================================\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=0.005,  # Learning rate um pouco maior para transfer learning\n",
        "    momentum=0.9,\n",
        "    weight_decay=0.0005\n",
        ")\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer,\n",
        "    step_size=3,\n",
        "    gamma=0.1\n",
        ")\n",
        "\n",
        "print(\"âœ… Otimizador configurado!\")\n",
        "print(f\"   ðŸ“Š Learning Rate: {optimizer.param_groups[0]['lr']}\")\n",
        "print(f\"   ðŸ“Š Momentum: 0.9\")\n",
        "print(f\"   ðŸ“Š Weight Decay: 0.0005\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# FUNÃ‡ÃƒO DE AVALIAÃ‡ÃƒO COCO\n",
        "# ================================================================\n",
        "\n",
        "def evaluate_coco(model, dataset, ann_path, device=\"cuda\", score_threshold=0.5):\n",
        "    model.eval()\n",
        "    coco_gt = COCO(ann_path)\n",
        "    \n",
        "    if 'info' not in coco_gt.dataset:\n",
        "        coco_gt.dataset['info'] = {\"description\": \"COCO Dataset\", \"version\": \"1.0\", \"year\": 2024}\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for img, target in dataset:\n",
        "        img_tensor = img.to(device).unsqueeze(0)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)[0]\n",
        "        \n",
        "        boxes = output[\"boxes\"].cpu().numpy()\n",
        "        scores = output[\"scores\"].cpu().numpy()\n",
        "        labels = output[\"labels\"].cpu().numpy()\n",
        "        \n",
        "        image_id = int(target[\"image_id\"].item())\n",
        "        \n",
        "        for box, score, label in zip(boxes, scores, labels):\n",
        "            if score >= score_threshold:\n",
        "                x1, y1, x2, y2 = box.tolist()\n",
        "                results.append({\n",
        "                    \"image_id\": image_id,\n",
        "                    \"category_id\": 1,  # Gun\n",
        "                    \"bbox\": [x1, y1, x2 - x1, y2 - y1],\n",
        "                    \"score\": float(score)\n",
        "                })\n",
        "    \n",
        "    if len(results) == 0:\n",
        "        return 0.0, 0.0\n",
        "    \n",
        "    coco_dt = coco_gt.loadRes(results)\n",
        "    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
        "    coco_eval.evaluate()\n",
        "    coco_eval.accumulate()\n",
        "    coco_eval.summarize()\n",
        "    \n",
        "    map50 = coco_eval.stats[1]\n",
        "    map5095 = coco_eval.stats[0]\n",
        "    \n",
        "    return map50, map5095\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# TREINAMENTO\n",
        "# ================================================================\n",
        "\n",
        "import os\n",
        "save_dir = \"runs/aula9_coco_gun\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "num_epochs = 10\n",
        "best_map = 0.0\n",
        "history = {\"train_loss\": [], \"map50\": [], \"map5095\": [], \"epoch\": []}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸš€ INICIANDO TREINAMENTO\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ðŸ“Š Ã‰pocas: {num_epochs}\")\n",
        "print(f\"ðŸ“Š Batch size: {BATCH_SIZE}\")\n",
        "print(f\"ðŸ“Š Dataset: 5% treino, 5% validaÃ§Ã£o\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    \n",
        "    print(f\"\\n[Ã‰poca {epoch+1}/{num_epochs}]\")\n",
        "    \n",
        "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
        "        imgs = [img.to(device) for img in imgs]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        \n",
        "        loss_dict = model(imgs, targets)\n",
        "        losses = sum(loss_dict.values())\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += losses.item()\n",
        "        \n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            print(f\"  Batch {batch_idx+1}/{len(train_loader)} - Loss: {losses.item():.4f}\")\n",
        "    \n",
        "    lr_scheduler.step()\n",
        "    \n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"  ðŸ“Š Loss mÃ©dio: {avg_loss:.4f}\")\n",
        "    \n",
        "    # AvaliaÃ§Ã£o\n",
        "    print(f\"  ðŸ” Avaliando...\")\n",
        "    map50, map5095 = evaluate_coco(\n",
        "        model,\n",
        "        val_dataset,\n",
        "        f\"{root_dir}/coco_annotations_val.json\",\n",
        "        device=device,\n",
        "        score_threshold=0.5\n",
        "    )\n",
        "    \n",
        "    print(f\"  âœ… mAP@0.5: {map50:.4f} | mAP@0.5:0.95: {map5095:.4f}\")\n",
        "    \n",
        "    history[\"train_loss\"].append(avg_loss)\n",
        "    history[\"map50\"].append(map50)\n",
        "    history[\"map5095\"].append(map5095)\n",
        "    history[\"epoch\"].append(epoch)\n",
        "    \n",
        "    # Salvar melhor modelo\n",
        "    if map50 > best_map:\n",
        "        best_map = map50\n",
        "        torch.save(model.state_dict(), f\"{save_dir}/best_model.pth\")\n",
        "        print(f\"  ðŸ’¾ Melhor modelo salvo! (mAP@0.5: {best_map:.4f})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… TREINAMENTO CONCLUÃDO!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# AVALIAÃ‡ÃƒO FINAL NO TESTE COM MÃ‰TRICAS COMPLETAS\n",
        "# ================================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸ” AVALIAÃ‡ÃƒO FINAL NO CONJUNTO DE TESTE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Carregar melhor modelo\n",
        "model.load_state_dict(torch.load(f\"{save_dir}/best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# MÃ©tricas COCO\n",
        "print(\"\\nðŸ“Š Calculando mÃ©tricas COCO...\")\n",
        "map50, map5095 = evaluate_coco(\n",
        "    model,\n",
        "    test_dataset,\n",
        "    f\"{root_dir}/coco_annotations_test.json\",\n",
        "    device=device,\n",
        "    score_threshold=0.5\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… MÃ©tricas COCO:\")\n",
        "print(f\"   ðŸŽ¯ mAP@0.5: {map50:.4f} ({map50*100:.2f}%)\")\n",
        "print(f\"   ðŸŽ¯ mAP@0.5:0.95: {map5095:.4f} ({map5095*100:.2f}%)\")\n",
        "\n",
        "# Calcular Precision e Recall\n",
        "print(\"\\nðŸ“Š Calculando Precision e Recall...\")\n",
        "\n",
        "all_pred_boxes = []\n",
        "all_pred_scores = []\n",
        "all_pred_labels = []\n",
        "all_gt_boxes = []\n",
        "all_gt_labels = []\n",
        "\n",
        "score_threshold = 0.5\n",
        "iou_threshold = 0.5\n",
        "\n",
        "for img, target in test_dataset:\n",
        "    img_tensor = img.to(device).unsqueeze(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)[0]\n",
        "    \n",
        "    mask = output[\"scores\"].cpu() >= score_threshold\n",
        "    pred_boxes = output[\"boxes\"].cpu()[mask]\n",
        "    pred_scores = output[\"scores\"].cpu()[mask]\n",
        "    pred_labels = output[\"labels\"].cpu()[mask]\n",
        "    \n",
        "    gt_boxes = target[\"boxes\"]\n",
        "    gt_labels = target[\"labels\"]\n",
        "    \n",
        "    all_pred_boxes.append(pred_boxes)\n",
        "    all_pred_scores.append(pred_scores)\n",
        "    all_pred_labels.append(pred_labels)\n",
        "    all_gt_boxes.append(gt_boxes)\n",
        "    all_gt_labels.append(gt_labels)\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    x1 = torch.max(box1[0], box2[0])\n",
        "    y1 = torch.max(box1[1], box2[1])\n",
        "    x2 = torch.min(box1[2], box2[2])\n",
        "    y2 = torch.min(box1[3], box2[3])\n",
        "    \n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return 0.0\n",
        "    \n",
        "    intersection = (x2 - x1) * (y2 - y1)\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "    union = area1 + area2 - intersection\n",
        "    \n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "total_tp = 0\n",
        "total_fp = 0\n",
        "total_fn = 0\n",
        "\n",
        "for pred_boxes, pred_labels, gt_boxes, gt_labels in zip(\n",
        "    all_pred_boxes, all_pred_labels, all_gt_boxes, all_gt_labels\n",
        "):\n",
        "    if len(gt_boxes) == 0:\n",
        "        total_fp += len(pred_boxes)\n",
        "        continue\n",
        "    \n",
        "    if len(pred_boxes) == 0:\n",
        "        total_fn += len(gt_boxes)\n",
        "        continue\n",
        "    \n",
        "    iou_matrix = torch.zeros(len(pred_boxes), len(gt_boxes))\n",
        "    for i, pred_box in enumerate(pred_boxes):\n",
        "        for j, gt_box in enumerate(gt_boxes):\n",
        "            iou_matrix[i, j] = calculate_iou(pred_box, gt_box)\n",
        "    \n",
        "    matched_gt = set()\n",
        "    for i in range(len(pred_boxes)):\n",
        "        best_iou = 0\n",
        "        best_gt_idx = -1\n",
        "        for j in range(len(gt_boxes)):\n",
        "            if j not in matched_gt and iou_matrix[i, j] > best_iou:\n",
        "                best_iou = iou_matrix[i, j]\n",
        "                best_gt_idx = j\n",
        "        \n",
        "        if best_iou >= iou_threshold and pred_labels[i] == gt_labels[best_gt_idx]:\n",
        "            total_tp += 1\n",
        "            matched_gt.add(best_gt_idx)\n",
        "        else:\n",
        "            total_fp += 1\n",
        "    \n",
        "    total_fn += len(gt_boxes) - len(matched_gt)\n",
        "\n",
        "precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
        "recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "print(f\"\\nâœ… MÃ©tricas de DetecÃ§Ã£o:\")\n",
        "print(f\"   ðŸŽ¯ Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"   ðŸŽ¯ Recall: {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"   ðŸŽ¯ F1-Score: {f1_score:.4f} ({f1_score*100:.2f}%)\")\n",
        "print(f\"\\n   ðŸ“Š EstatÃ­sticas:\")\n",
        "print(f\"      âœ… True Positives (TP): {total_tp}\")\n",
        "print(f\"      âŒ False Positives (FP): {total_fp}\")\n",
        "print(f\"      âš ï¸  False Negatives (FN): {total_fn}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ“‹ RESUMO FINAL\")\n",
        "print(\"=\"*60)\n",
        "print(f\"âœ… mAP@0.5:        {map50:.4f} ({map50*100:.2f}%)\")\n",
        "print(f\"âœ… mAP@0.5:0.95:   {map5095:.4f} ({map5095*100:.2f}%)\")\n",
        "print(f\"âœ… Precision:      {precision:.4f} ({precision*100:.2f}%)\")\n",
        "print(f\"âœ… Recall:         {recall:.4f} ({recall*100:.2f}%)\")\n",
        "print(f\"âœ… F1-Score:       {f1_score:.4f} ({f1_score*100:.2f}%)\")\n",
        "print(f\"\\nðŸ“Š DetecÃ§Ãµes:\")\n",
        "print(f\"   âœ… TP: {total_tp} | âŒ FP: {total_fp} | âš ï¸  FN: {total_fn}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================================================\n",
        "# VISUALIZAÃ‡ÃƒO DE RESULTADOS\n",
        "# ================================================================\n",
        "\n",
        "print(\"ðŸ–¼ï¸  Gerando visualizaÃ§Ãµes...\")\n",
        "\n",
        "def visualize_predictions(dataset, model, num_images=6, score_threshold=0.5):\n",
        "    model.eval()\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    indices = np.random.choice(len(dataset), min(num_images, len(dataset)), replace=False)\n",
        "    \n",
        "    for idx, ax in enumerate(axes):\n",
        "        if idx >= len(indices):\n",
        "            ax.axis('off')\n",
        "            continue\n",
        "            \n",
        "        img, target = dataset[indices[idx]]\n",
        "        img_tensor = img.to(device).unsqueeze(0)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output = model(img_tensor)[0]\n",
        "        \n",
        "        img_np = img.cpu().permute(1, 2, 0).numpy()\n",
        "        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        img_np = np.clip(img_np, 0, 1)\n",
        "        \n",
        "        ax.imshow(img_np)\n",
        "        ax.axis('off')\n",
        "        \n",
        "        # Ground truth (verde)\n",
        "        for box, label in zip(target[\"boxes\"], target[\"labels\"]):\n",
        "            x1, y1, x2, y2 = box.numpy()\n",
        "            rect = patches.Rectangle(\n",
        "                (x1, y1), x2-x1, y2-y1,\n",
        "                linewidth=2, edgecolor='green', facecolor='none', linestyle='--'\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "            ax.text(x1, y1-5, 'GT', color='green', fontsize=8, weight='bold')\n",
        "        \n",
        "        # PrediÃ§Ãµes (vermelho)\n",
        "        mask = output[\"scores\"].cpu() >= score_threshold\n",
        "        pred_boxes = output[\"boxes\"].cpu()[mask]\n",
        "        pred_scores = output[\"scores\"].cpu()[mask]\n",
        "        \n",
        "        for box, score in zip(pred_boxes, pred_scores):\n",
        "            x1, y1, x2, y2 = box.numpy()\n",
        "            rect = patches.Rectangle(\n",
        "                (x1, y1), x2-x1, y2-y1,\n",
        "                linewidth=2, edgecolor='red', facecolor='none'\n",
        "            )\n",
        "            ax.add_patch(rect)\n",
        "            ax.text(x1, y1-5, f'{score:.2f}', color='red', fontsize=8, weight='bold')\n",
        "        \n",
        "        ax.set_title(f'Imagem {indices[idx]}', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{save_dir}/predictions.png\", dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"âœ… VisualizaÃ§Ãµes salvas em: {save_dir}/predictions.png\")\n",
        "\n",
        "visualize_predictions(test_dataset, model, num_images=6, score_threshold=0.5)\n",
        "print(\"âœ… VisualizaÃ§Ã£o concluÃ­da!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
