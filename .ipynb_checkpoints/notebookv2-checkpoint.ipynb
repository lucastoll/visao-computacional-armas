{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10235471,"sourceType":"datasetVersion","datasetId":6329026}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style='background-color: #fff7f7; border: 3px solid Red;'>\n    <font size=\"+1\" color=\"Red\">\n        <b>Please comment and upvote if you like this work!</b>\n    </font>\n</div>\n<div style='background-color: #fff7f7; border: 3px solid Blue;'>\n    <font size=\"+1\" color=\"Red\">\n        <b>Take a look at the other notebooks in my profile ->\n        <a href=\"https://www.kaggle.com/killa92/code\">  Kaggle Notebooks </a></b>\n    </font>\n</div>    \n<div style='background-color: #fff7f7; border: 3px solid yellow;'>\n    <font size=\"+1\" color=\"Red\">\n        <b><span style='color: green;'>Let's Support Each Other!!</span></b>\n    </font>\n</div>","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"<div style='background-color: #fff7f7; border: 2px solid '>\n    <font size=\"+2\" color=\"blue\" ><b>üóÇÔ∏è1. Install libraries and Download a pre-trained checkpoint üóÇÔ∏è</b></font>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install ultralytics\nfrom ultralytics import YOLO\nmodel = YOLO(\"yolo11n.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:33:10.125707Z","iopub.execute_input":"2024-12-19T05:33:10.126113Z","iopub.status.idle":"2024-12-19T05:33:21.38706Z","shell.execute_reply.started":"2024-12-19T05:33:10.12607Z","shell.execute_reply":"2024-12-19T05:33:21.386298Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" <div style='background-color: #fff7f7; border: 2px solid '>\n    <font size=\"+2\" color=\"blue\" ><b>üìà 2. Data Preparation and Data Analysisüìà</b></font>\n</div>","metadata":{}},{"cell_type":"code","source":"from glob import glob\nimport os\n\nHOME = \"/kaggle/working\"\ndef make_ds(root, path_to_copy):\n    \n    os.makedirs(path_to_copy, exist_ok = True)\n    \n    files = glob(f\"{root}/*\")\n    for idx, file in enumerate(files):\n        if os.path.isdir(file): os.system(f\"cp -r '{file}' {path_to_copy}\")\n        elif os.path.isfile(file): os.system(f\"cp '{file}' {path_to_copy}\")\n            \nroot = \"/kaggle/input/guns-and-knifes-detection-in-cctv-videos/combined_gunsnknifes\"\nmake_ds(root = root, path_to_copy = f\"{HOME}/datasets\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:33:46.475652Z","iopub.execute_input":"2024-12-19T05:33:46.476068Z","iopub.status.idle":"2024-12-19T05:36:07.464586Z","shell.execute_reply.started":"2024-12-19T05:33:46.476042Z","shell.execute_reply":"2024-12-19T05:36:07.463627Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style='background-color: #fff7f7; border: 2px solid '>\n    <font size=\"+2\" color=\"blue\" ><b>üìä 3. Data Visualization üìä</b></font>\n</div>","metadata":{}},{"cell_type":"code","source":"import cv2, yaml, random, numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nfrom torchvision import transforms as T\n\nclass Visualization:\n\n    def __init__(self, data_types, n_ims, rows, cmap = None):\n\n        self.n_ims, self.rows = n_ims, rows\n        self.cmap, self.data_types  = cmap, data_types\n        self.colors = [\"firebrick\", \"darkorange\", \"blueviolet\"]\n        \n        self.get_cls_names(); self.get_bboxes()        \n                \n    def get_cls_names(self):\n\n        with open(f\"{HOME}/datasets/data.yaml\", 'r') as file: data = yaml.safe_load(file)      \n        # Extract class names\n        class_names = data['names']\n        \n        # Create a dictionary with index as key and class name as value\n        self.class_dict = {index: name for index, name in enumerate(class_names)}        \n    \n    def get_bboxes(self):\n\n        self.vis_datas, self.analysis_datas, self.im_paths = {}, {}, {}\n        for data_type in self.data_types:\n            all_bboxes, all_analysis_datas = [], {}\n            im_paths = glob(f\"{HOME}/datasets/{data_type}/images/*\")\n            for idx, im_path in enumerate(im_paths):\n                bboxes = []\n                # if idx == 3: break\n                lbl_path  = im_path.replace(\"images\", \"labels\").replace(\".jpg\", \".txt\")\n                if not os.path.isfile(lbl_path): continue\n                meta_data = open(lbl_path).readlines()\n                for data in meta_data:\n                    # Split the string by space and strip the newline character\n                    # Change here \n                    parts = data.strip().split()[:5]\n                    cls_name = self.class_dict[int(parts[0])]\n                    # Convert first element to integer and the rest to float\n                    bboxes.append([cls_name] + [float(x) for x in parts[1:]])\n                    if cls_name not in all_analysis_datas: all_analysis_datas[cls_name] = 1\n                    else: all_analysis_datas[cls_name] += 1\n                all_bboxes.append(bboxes)\n                    \n            self.vis_datas[data_type] = all_bboxes; self.analysis_datas[data_type] = all_analysis_datas; self.im_paths[data_type] = im_paths\n    \n    def plot(self, rows, cols, count, im_path, bboxes):\n    \n        plt.subplot(rows, cols, count)\n        or_im = np.array(Image.open(im_path).convert(\"RGB\"))\n        height, width, _ = or_im.shape\n\n        for bbox in bboxes:\n            \n            class_id, x_center, y_center, w, h = bbox\n\n            # Convert YOLO format to pixel values\n            x_min = int((x_center - w / 2) * width)  # x_min\n            y_min = int((y_center - h / 2) * height)  # y_min\n            x_max = int((x_center + w / 2) * width)  # x_max\n            y_max = int((y_center + h / 2) * height)  # y_max\n            \n            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n            cv2.rectangle(img = or_im, pt1 = (x_min, y_min), pt2 = (x_max, y_max), color = color, thickness = 3)\n        plt.imshow(or_im)\n        plt.axis(\"off\"); plt.title(f\"There are {len(bboxes)} object(s) in the image.\")\n        \n        return count + 1\n\n    def vis(self, save_name):\n\n        print(f\"{save_name.upper()} Data Visualization is in process...\\n\")\n        assert self.cmap in [\"rgb\", \"gray\"], \"Please choose rgb or gray cmap\"\n        if self.cmap == \"rgb\": cmap = \"viridis\"\n        cols = self.n_ims // self.rows; count = 1\n        \n        plt.figure(figsize = (25, 20))\n                \n        indices = [random.randint(a = 0, b = len(self.vis_datas[save_name]) - 1) for _ in range(self.n_ims)]\n\n        for idx, index in enumerate(indices):\n        \n            if count == self.n_ims + 1: break\n            \n            im_path, bboxes = self.im_paths[save_name][index], self.vis_datas[save_name][index]\n\n            count = self.plot(self.rows, cols, count, im_path = im_path, bboxes = bboxes)\n            \n        plt.show()\n\n    def data_analysis(self, save_name, color):\n\n        print(\"Data analysis is in process...\\n\")\n        \n        width, text_width, text_height = 0.7, 0.05, 2\n        cls_names = list(self.analysis_datas[save_name].keys()); counts = list(self.analysis_datas[save_name].values())\n        \n        _, ax = plt.subplots(figsize = (30, 10))\n        indices = np.arange(len(counts))\n\n        ax.bar(indices, counts, width, color = color)\n        ax.set_xlabel(\"Class Names\", color = \"black\")\n        ax.set_xticklabels(cls_names)\n        ax.set(xticks = indices, xticklabels = cls_names)\n        ax.set_ylabel(\"Data Counts\", color = \"black\")\n        ax.set_title(f\"{save_name.upper()} Dataset Class Imbalance Analysis\")\n\n        for i, v in enumerate(counts): ax.text(i - text_width, v + text_height, str(v), color = \"royalblue\")\n    \n    def visualization(self): [self.vis(save_name) for save_name in self.data_types]\n        \n    def analysis(self): [self.data_analysis(save_name, color) for (save_name, color) in zip(self.data_types, self.colors)]\n        \nvis = Visualization(data_types = [\"train\", \"val\", \"test\"], n_ims = 20, rows = 5, cmap = \"rgb\")\nvis.analysis()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:37:44.869233Z","iopub.execute_input":"2024-12-19T05:37:44.869595Z","iopub.status.idle":"2024-12-19T05:37:46.031551Z","shell.execute_reply.started":"2024-12-19T05:37:44.869569Z","shell.execute_reply":"2024-12-19T05:37:46.030747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vis.visualization()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:37:49.436782Z","iopub.execute_input":"2024-12-19T05:37:49.437108Z","iopub.status.idle":"2024-12-19T05:37:57.579309Z","shell.execute_reply.started":"2024-12-19T05:37:49.43708Z","shell.execute_reply":"2024-12-19T05:37:57.578334Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style='background-color: #fff7f7; border: 2px solid '>\n    <font size=\"+2\" color=\"blue\" ><b>‚ú® 4. AI Model Train‚ú®</b></font>\n</div>","metadata":{}},{"cell_type":"code","source":"train_results = model.train(\n    data=f\"{HOME}/datasets/data.yaml\",  # path to dataset YAML\n    epochs=10,  # number of training epochs\n    imgsz=480,  # training image size\n    device=[0,1]  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:38:45.335706Z","iopub.execute_input":"2024-12-19T05:38:45.33599Z","iopub.status.idle":"2024-12-19T05:52:19.371563Z","shell.execute_reply.started":"2024-12-19T05:38:45.335968Z","shell.execute_reply":"2024-12-19T05:52:19.370787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style='background-color: #fff7f7; border: 2px solid '>\n    <font size=\"+2\" color=\"blue\" ><b>üòç 5. Learning Curves üòç</b></font>\n</div>","metadata":{}},{"cell_type":"code","source":"Image.open(f\"runs/detect/train/confusion_matrix.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:52:19.372607Z","iopub.execute_input":"2024-12-19T05:52:19.373186Z","iopub.status.idle":"2024-12-19T05:52:19.694581Z","shell.execute_reply.started":"2024-12-19T05:52:19.373157Z","shell.execute_reply":"2024-12-19T05:52:19.693654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image.open(f\"runs/detect/train/results.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:52:19.696005Z","iopub.execute_input":"2024-12-19T05:52:19.696235Z","iopub.status.idle":"2024-12-19T05:52:19.870483Z","shell.execute_reply.started":"2024-12-19T05:52:19.696216Z","shell.execute_reply":"2024-12-19T05:52:19.86958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image.open(f\"runs/detect/train/P_curve.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:52:19.871744Z","iopub.execute_input":"2024-12-19T05:52:19.872027Z","iopub.status.idle":"2024-12-19T05:52:20.084391Z","shell.execute_reply.started":"2024-12-19T05:52:19.872001Z","shell.execute_reply":"2024-12-19T05:52:20.08356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image.open(f\"runs/detect/train/PR_curve.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:52:20.085103Z","iopub.execute_input":"2024-12-19T05:52:20.085347Z","iopub.status.idle":"2024-12-19T05:52:20.288065Z","shell.execute_reply.started":"2024-12-19T05:52:20.085328Z","shell.execute_reply":"2024-12-19T05:52:20.287202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image.open(f\"runs/detect/train/val_batch0_pred.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:52:20.288893Z","iopub.execute_input":"2024-12-19T05:52:20.289126Z","iopub.status.idle":"2024-12-19T05:52:20.840713Z","shell.execute_reply.started":"2024-12-19T05:52:20.289107Z","shell.execute_reply":"2024-12-19T05:52:20.839229Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style='background-color: #fff7f7; border: 2px solid '>\n    <font size=\"+2\" color=\"blue\" ><b>‚úÖ6. Inference with Train Dataset‚úÖ</b></font>\n</div>","metadata":{}},{"cell_type":"code","source":"inference_results = model(\"datasets/test/images\", device = 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T05:52:20.841457Z","iopub.execute_input":"2024-12-19T05:52:20.841684Z","iopub.status.idle":"2024-12-19T05:52:25.705636Z","shell.execute_reply.started":"2024-12-19T05:52:20.841666Z","shell.execute_reply":"2024-12-19T05:52:25.704803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def inference_vis(res, n_ims, rows):\n    cols = n_ims // rows\n    plt.figure(figsize = (20, 10))\n    for idx, r in enumerate(res):\n        if idx == n_ims: break\n        plt.subplot(rows, cols, idx + 1)\n        or_im_rgb = np.array(Image.open(r.path).convert(\"RGB\"))\n        if idx == n_ims: break    \n        for i in r:\n            for bbox in i.boxes:\n                box = bbox.xyxy[0]\n                x1, y1, x2, y2 = box\n                coord1, coord2 = (int(x1), int(y1)), (int(x2), int(y2))\n                cv2.rectangle(or_im_rgb, coord1, coord2, color=(255,0,0), thickness=2)\n        plt.imshow(or_im_rgb)\n        plt.title(f\"Image#{idx + 1}\")\n        plt.axis(\"off\")\ninference_vis(res = inference_results, n_ims = 15, rows = 3)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}