{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #f0f8ff; border: 3px solid Blue;'>\n",
    "    <font size=\"+1\" color=\"Blue\">\n",
    "        <b>üöÄ Notebook de Treinamento SSD (Single Shot Multibox Detector) para Detec√ß√£o de Armas</b>\n",
    "    </font>\n",
    "</div>\n",
    "<div style='background-color: #fff7f7; border: 2px solid Green;'>\n",
    "    <font size=\"+1\" color=\"Green\">\n",
    "        <b>‚úÖ Dataset configurado: dataset_final (formato YOLO)</b>\n",
    "    </font>\n",
    "</div>\n",
    "<div style='background-color: #fffacd; border: 2px solid Orange;'>\n",
    "    <font size=\"+1\" color=\"Orange\">\n",
    "        <b>üì¶ Modelo: SSD Lite 320 com MobileNet V3 Large</b>\n",
    "        <br>O modelo ser√° baixado automaticamente na primeira execu√ß√£o (weights='DEFAULT' ou 'COCO_V1')\n",
    "    </font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #fff7f7; border: 2px solid '>\n",
    "    <font size=\"+2\" color=\"blue\" ><b>1. Instalar bibliotecas e carregar modelo pr√©-treinado</b></font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --upgrade -q\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import ssdlite320_mobilenet_v3_large\n",
    "from torchvision.models.detection.ssd import SSDClassificationHead\n",
    "from torchvision.models.detection import SSDLite320_MobileNet_V3_Large_Weights\n",
    "\n",
    "# Verifica GPU\n",
    "print(\"üîç Verificando GPU...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GPU n√£o dispon√≠vel - usando CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Carrega modelo SSD pr√©-treinado\n",
    "# O modelo ser√° baixado automaticamente na primeira execu√ß√£o\n",
    "print(\"\\nüì¶ Carregando modelo SSD Lite 320 com MobileNet V3 Large...\")\n",
    "print(\"üí° Nome do modelo: ssdlite320_mobilenet_v3_large\")\n",
    "print(\"üí° Pesos pr√©-treinados: SSDLite320_MobileNet_V3_Large_Weights.DEFAULT (COCO)\")\n",
    "weights = SSDLite320_MobileNet_V3_Large_Weights.DEFAULT\n",
    "model = ssdlite320_mobilenet_v3_large(weights=weights)\n",
    "print(f\"‚úÖ Modelo SSD carregado com sucesso!\")\n",
    "print(f\"üìä Modelo pr√©-treinado em: {weights}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #fff7f7; border: 2px solid '>\n",
    "    <font size=\"+2\" color=\"blue\" ><b>2. Configura√ß√£o do Dataset</b></font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Define o diret√≥rio base e caminhos do dataset\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset_final\")\n",
    "DATASET_YAML = os.path.join(DATASET_DIR, \"dataset.yaml\")\n",
    "\n",
    "print(f\"üìÅ Diret√≥rio base: {BASE_DIR}\")\n",
    "print(f\"üìÅ Dataset: {DATASET_DIR}\")\n",
    "print(f\"üìÑ Dataset YAML: {DATASET_YAML}\")\n",
    "\n",
    "# Verifica se o dataset existe\n",
    "if os.path.exists(DATASET_YAML):\n",
    "    print(\"‚úÖ Dataset encontrado!\")\n",
    "    \n",
    "    # L√™ classes do YAML\n",
    "    with open(DATASET_YAML, 'r', encoding='utf-8') as file:\n",
    "        data = yaml.safe_load(file)\n",
    "    class_names = data['names']\n",
    "    num_classes = len(class_names)\n",
    "    print(f\"‚úÖ Classes encontradas: {class_names}\")\n",
    "    print(f\"‚úÖ N√∫mero de classes: {num_classes}\")\n",
    "    \n",
    "    # Conta arquivos\n",
    "    train_path = os.path.join(DATASET_DIR, \"train\", \"images\")\n",
    "    val_path = os.path.join(DATASET_DIR, \"val\", \"images\")\n",
    "    test_path = os.path.join(DATASET_DIR, \"test\", \"images\")\n",
    "    \n",
    "    train_images = len([f for f in os.listdir(train_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(train_path) else 0\n",
    "    val_images = len([f for f in os.listdir(val_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(val_path) else 0\n",
    "    test_images = len([f for f in os.listdir(test_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(test_path) else 0\n",
    "    \n",
    "    print(f\"üìä Imagens de treino: {train_images}\")\n",
    "    print(f\"üìä Imagens de valida√ß√£o: {val_images}\")\n",
    "    print(f\"üìä Imagens de teste: {test_images}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o encontrado! Verifique o caminho.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #fff7f7; border: 2px solid '>\n",
    "    <font size=\"+2\" color=\"blue\" ><b>3. Criar Dataset Customizado (YOLO ‚Üí SSD)</b></font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "class YOLODataset(Dataset):\n",
    "    \"\"\"Dataset customizado que converte formato YOLO para formato SSD\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_dir, split='train', transform=None, img_size=320):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.split = split\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Carrega nomes das classes\n",
    "        yaml_path = os.path.join(dataset_dir, 'dataset.yaml')\n",
    "        with open(yaml_path, 'r', encoding='utf-8') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        self.class_names = data['names']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        \n",
    "        # Busca todas as imagens\n",
    "        images_dir = os.path.join(dataset_dir, split, 'images')\n",
    "        labels_dir = os.path.join(dataset_dir, split, 'labels')\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.label_paths = []\n",
    "        \n",
    "        for img_path in glob(os.path.join(images_dir, '*')):\n",
    "            if img_path.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                # Encontra label correspondente\n",
    "                label_path = img_path.replace('images', 'labels')\n",
    "                for ext in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']:\n",
    "                    label_path = label_path.replace(ext, '.txt')\n",
    "                \n",
    "                if os.path.exists(label_path):\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.label_paths.append(label_path)\n",
    "        \n",
    "        print(f\"‚úÖ Carregados {len(self.image_paths)} pares imagem/label para {split}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Carrega imagem\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        original_width, original_height = image.size\n",
    "        \n",
    "        # Redimensiona imagem para 320x320 (tamanho esperado pelo SSD)\n",
    "        image = image.resize((self.img_size, self.img_size))\n",
    "        scale_x = self.img_size / original_width\n",
    "        scale_y = self.img_size / original_height\n",
    "        \n",
    "        # Carrega labels YOLO\n",
    "        label_path = self.label_paths[idx]\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    \n",
    "                    # Converte YOLO (normalizado centro, largura, altura) para Pascal VOC (x_min, y_min, x_max, y_max)\n",
    "                    x_min = (x_center - width / 2) * original_width * scale_x\n",
    "                    y_min = (y_center - height / 2) * original_height * scale_y\n",
    "                    x_max = (x_center + width / 2) * original_width * scale_x\n",
    "                    y_max = (y_center + height / 2) * original_height * scale_y\n",
    "                    \n",
    "                    boxes.append([x_min, y_min, x_max, y_max])\n",
    "                    labels.append(class_id + 1)  # +1 porque SSD usa 0 para background\n",
    "        \n",
    "        # Converte para tensores\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32) if boxes else torch.zeros((0, 4), dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64) if labels else torch.zeros((0,), dtype=torch.int64)\n",
    "        \n",
    "        # Aplica transforma√ß√µes\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': torch.tensor([idx]),\n",
    "            'area': (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]) if len(boxes) > 0 else torch.zeros((0,), dtype=torch.float32),\n",
    "            'iscrowd': torch.zeros((len(boxes),), dtype=torch.int64) if len(boxes) > 0 else torch.zeros((0,), dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# Cria datasets\n",
    "print(\"\\nüì¶ Criando datasets...\")\n",
    "train_dataset = YOLODataset(DATASET_DIR, split='train', img_size=320)\n",
    "val_dataset = YOLODataset(DATASET_DIR, split='val', img_size=320)\n",
    "test_dataset = YOLODataset(DATASET_DIR, split='test', img_size=320)\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets criados com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O modelo pr√©-treinado tem 91 classes (COCO), precisamos ajustar para nosso n√∫mero de classes\n",
    "# SSD precisa de num_classes + 1 (incluindo background)\n",
    "num_classes_custom = num_classes + 1  # +1 para background\n",
    "\n",
    "print(f\"üìä Ajustando modelo para {num_classes} classes (+1 background = {num_classes_custom} total)\")\n",
    "\n",
    "# Obt√©m o n√∫mero de classes do modelo atual\n",
    "num_classes_pretrained = model.head.classification_head.cls_logits.out_channels // model.head.classification_head.num_anchors\n",
    "print(f\"üìä Modelo pr√©-treinado tem {num_classes_pretrained} classes\")\n",
    "\n",
    "# Substitui o head de classifica√ß√£o\n",
    "from torchvision.models.detection.ssd import SSDClassificationHead\n",
    "\n",
    "# Obt√©m configura√ß√£o do head atual\n",
    "in_channels = model.head.classification_head.cls_logits.in_channels\n",
    "num_anchors = model.head.classification_head.num_anchors\n",
    "\n",
    "# Cria novo head de classifica√ß√£o\n",
    "model.head.classification_head = SSDClassificationHead(\n",
    "    in_channels=in_channels,\n",
    "    num_anchors=num_anchors,\n",
    "    num_classes=num_classes_custom\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Modelo ajustado para {num_classes} classes!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #fff7f7; border: 2px solid '>\n",
    "    <font size=\"+2\" color=\"blue\" ><b>5. Visualiza√ß√£o dos Dados</b></font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Visualizacao:\n",
    "    def __init__(self, data_types, n_ims, rows, cmap=None):\n",
    "        self.n_ims, self.rows = n_ims, rows\n",
    "        self.cmap, self.data_types = cmap, data_types\n",
    "        self.colors = [\"firebrick\", \"darkorange\", \"blueviolet\"]\n",
    "        \n",
    "        self.get_cls_names()\n",
    "        self.get_bboxes()        \n",
    "                \n",
    "    def get_cls_names(self):\n",
    "        with open(DATASET_YAML, 'r', encoding='utf-8') as file:\n",
    "            data = yaml.safe_load(file)\n",
    "        class_names = data['names']\n",
    "        self.class_dict = {index: name for index, name in enumerate(class_names)}\n",
    "        print(f\"‚úÖ Classes encontradas: {list(self.class_dict.values())}\")\n",
    "    \n",
    "    def get_bboxes(self):\n",
    "        self.vis_datas, self.analysis_datas, self.im_paths = {}, {}, {}\n",
    "        \n",
    "        for data_type in self.data_types:\n",
    "            all_bboxes, all_analysis_datas = [], {}\n",
    "            im_paths = glob(os.path.join(DATASET_DIR, data_type, \"images\", \"*\"))\n",
    "            im_paths = [p for p in im_paths if p.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            for idx, im_path in enumerate(im_paths):\n",
    "                bboxes = []\n",
    "                lbl_path = im_path.replace(\"images\", \"labels\")\n",
    "                for ext in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']:\n",
    "                    lbl_path = lbl_path.replace(ext, \".txt\")\n",
    "                \n",
    "                if not os.path.isfile(lbl_path):\n",
    "                    continue\n",
    "                    \n",
    "                meta_data = open(lbl_path, 'r').readlines()\n",
    "                for data in meta_data:\n",
    "                    parts = data.strip().split()[:5]\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                    cls_name = self.class_dict[int(parts[0])]\n",
    "                    bboxes.append([cls_name] + [float(x) for x in parts[1:]])\n",
    "                    if cls_name not in all_analysis_datas:\n",
    "                        all_analysis_datas[cls_name] = 1\n",
    "                    else:\n",
    "                        all_analysis_datas[cls_name] += 1\n",
    "                all_bboxes.append(bboxes)\n",
    "                    \n",
    "            self.vis_datas[data_type] = all_bboxes\n",
    "            self.analysis_datas[data_type] = all_analysis_datas\n",
    "            self.im_paths[data_type] = im_paths\n",
    "    \n",
    "    def plot(self, rows, cols, count, im_path, bboxes):\n",
    "        plt.subplot(rows, cols, count)\n",
    "        or_im = np.array(Image.open(im_path).convert(\"RGB\"))\n",
    "        height, width, _ = or_im.shape\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            class_id, x_center, y_center, w, h = bbox\n",
    "            x_min = int((x_center - w / 2) * width)\n",
    "            y_min = int((y_center - h / 2) * height)\n",
    "            x_max = int((x_center + w / 2) * width)\n",
    "            y_max = int((y_center + h / 2) * height)\n",
    "            \n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            cv2.rectangle(img=or_im, pt1=(x_min, y_min), pt2=(x_max, y_max), color=color, thickness=3)\n",
    "        \n",
    "        plt.imshow(or_im)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"H√° {len(bboxes)} objeto(s) na imagem.\")\n",
    "        \n",
    "        return count + 1\n",
    "\n",
    "    def vis(self, save_name):\n",
    "        print(f\"üìä Visualiza√ß√£o de dados {save_name.upper()} em processo...\\n\")\n",
    "        cols = self.n_ims // self.rows\n",
    "        count = 1\n",
    "        \n",
    "        plt.figure(figsize=(25, 20))\n",
    "        \n",
    "        if len(self.vis_datas[save_name]) == 0:\n",
    "            print(f\"‚ö†Ô∏è  Nenhuma imagem encontrada para {save_name}\")\n",
    "            return\n",
    "            \n",
    "        indices = [random.randint(a=0, b=len(self.vis_datas[save_name]) - 1) for _ in range(min(self.n_ims, len(self.vis_datas[save_name])))]\n",
    "\n",
    "        for idx, index in enumerate(indices):\n",
    "            if count == self.n_ims + 1:\n",
    "                break\n",
    "            \n",
    "            im_path = self.im_paths[save_name][index]\n",
    "            bboxes = self.vis_datas[save_name][index]\n",
    "            count = self.plot(self.rows, cols, count, im_path=im_path, bboxes=bboxes)\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    def data_analysis(self, save_name, color):\n",
    "        print(f\"üìà An√°lise de dados {save_name} em processo...\\n\")\n",
    "        \n",
    "        if save_name not in self.analysis_datas or len(self.analysis_datas[save_name]) == 0:\n",
    "            print(f\"‚ö†Ô∏è  Nenhum dado encontrado para {save_name}\")\n",
    "            return\n",
    "        \n",
    "        width, text_width, text_height = 0.7, 0.05, 2\n",
    "        cls_names = list(self.analysis_datas[save_name].keys())\n",
    "        counts = list(self.analysis_datas[save_name].values())\n",
    "        \n",
    "        _, ax = plt.subplots(figsize=(30, 10))\n",
    "        indices = np.arange(len(counts))\n",
    "\n",
    "        ax.bar(indices, counts, width, color=color)\n",
    "        ax.set_xlabel(\"Nomes das Classes\", color=\"black\")\n",
    "        ax.set(xticks=indices, xticklabels=cls_names)\n",
    "        ax.set_ylabel(\"Quantidade de Dados\", color=\"black\")\n",
    "        ax.set_title(f\"An√°lise de Desbalanceamento de Classes - Dataset {save_name.upper()}\")\n",
    "\n",
    "        for i, v in enumerate(counts):\n",
    "            ax.text(i - text_width, v + text_height, str(v), color=\"royalblue\")\n",
    "        plt.show()\n",
    "    \n",
    "    def visualization(self):\n",
    "        [self.vis(save_name) for save_name in self.data_types]\n",
    "        \n",
    "    def analysis(self):\n",
    "        [self.data_analysis(save_name, color) for (save_name, color) in zip(self.data_types, self.colors)]\n",
    "        \n",
    "# Cria visualiza√ß√£o\n",
    "vis = Visualizacao(data_types=[\"train\", \"val\", \"test\"], n_ims=20, rows=5, cmap=\"rgb\")\n",
    "vis.analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza imagens com bounding boxes\n",
    "vis.visualization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Fun√ß√£o de collate para DataLoader\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)\n",
    "    return list(images), list(targets)\n",
    "\n",
    "# Transforma√ß√µes para treinamento\n",
    "def get_transform(train):\n",
    "    transforms_list = []\n",
    "    if train:\n",
    "        transforms_list.append(transforms.RandomHorizontalFlip(0.5))\n",
    "    transforms_list.append(transforms.ToTensor())\n",
    "    transforms_list.append(transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]))\n",
    "    return transforms.Compose(transforms_list)\n",
    "\n",
    "# Atualiza datasets com transforma√ß√µes\n",
    "train_dataset.transform = get_transform(train=True)\n",
    "val_dataset.transform = get_transform(train=False)\n",
    "\n",
    "# Cria DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, collate_fn=collate_fn)\n",
    "\n",
    "# Move modelo para device\n",
    "model = model.to(device)\n",
    "\n",
    "# Otimizador\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(\"‚úÖ DataLoaders e otimizador configurados!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de treinamento\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += losses.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Fun√ß√£o de valida√ß√£o\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = [img.to(device) for img in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            \n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            total_loss += losses.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# Treinamento\n",
    "num_epochs = 50\n",
    "best_loss = float('inf')\n",
    "os.makedirs('runs/ssd', exist_ok=True)\n",
    "\n",
    "print(f\"üöÄ Iniciando treinamento √†s {datetime.now().strftime('%H:%M:%S')}\")\n",
    "if device.type == 'cuda':\n",
    "    print(\"üöÄ Usando GPU - treinamento ser√° muito mais r√°pido!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Usando CPU - treinamento ser√° MUITO lento!\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, optimizer, train_loader, device, epoch)\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Salva melhor modelo\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'runs/ssd/best_model.pth')\n",
    "        print(f\"  ‚úÖ Novo melhor modelo salvo! (Loss: {best_loss:.4f})\")\n",
    "\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "hours = int(total_time // 3600)\n",
    "minutes = int((total_time % 3600) // 60)\n",
    "seconds = int(total_time % 60)\n",
    "print(f\"\\n‚úÖ Treinamento conclu√≠do em {hours}h {minutes}m {seconds}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background-color: #fff7f7; border: 2px solid '>\n",
    "    <font size=\"+2\" color=\"blue\" ><b>7. Infer√™ncia com Dataset de Teste</b></font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega melhor modelo\n",
    "if os.path.exists('runs/ssd/best_model.pth'):\n",
    "    model.load_state_dict(torch.load('runs/ssd/best_model.pth'))\n",
    "    print(\"‚úÖ Melhor modelo carregado!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Modelo n√£o encontrado. Execute o treinamento primeiro.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Executa infer√™ncia\n",
    "test_images_path = os.path.join(DATASET_DIR, \"test\", \"images\")\n",
    "test_image_files = [f for f in os.listdir(test_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))][:50]  # Limita a 50 para demonstra√ß√£o\n",
    "\n",
    "print(f\"üîç Executando infer√™ncia em {len(test_image_files)} imagens de teste...\")\n",
    "\n",
    "results = []\n",
    "transform = get_transform(train=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_file in test_image_files:\n",
    "        img_path = os.path.join(test_images_path, img_file)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        predictions = model(img_tensor)\n",
    "        \n",
    "        results.append({\n",
    "            'path': img_path,\n",
    "            'image': image,\n",
    "            'predictions': predictions[0]\n",
    "        })\n",
    "\n",
    "print(f\"‚úÖ Infer√™ncia conclu√≠da em {len(results)} imagens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza resultados\n",
    "def visualizar_inferencia_ssd(results, n_ims=15, rows=3, conf_threshold=0.5):\n",
    "    \"\"\"Visualiza resultados da infer√™ncia SSD\"\"\"\n",
    "    cols = n_ims // rows\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    for idx, result in enumerate(results[:n_ims]):\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        or_im_rgb = np.array(result['image'].convert(\"RGB\"))\n",
    "        \n",
    "        boxes = result['predictions']['boxes'].cpu().numpy()\n",
    "        scores = result['predictions']['scores'].cpu().numpy()\n",
    "        labels = result['predictions']['labels'].cpu().numpy()\n",
    "        \n",
    "        # Filtra por confian√ßa\n",
    "        mask = scores >= conf_threshold\n",
    "        boxes = boxes[mask]\n",
    "        scores = scores[mask]\n",
    "        labels = labels[mask]\n",
    "        \n",
    "        # Desenha bounding boxes\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "            coord1, coord2 = (x1, y1), (x2, y2)\n",
    "            \n",
    "            # Desenha ret√¢ngulo\n",
    "            cv2.rectangle(or_im_rgb, coord1, coord2, color=(255, 0, 0), thickness=2)\n",
    "            \n",
    "            # Adiciona label com confian√ßa\n",
    "            class_name = class_names[label - 1] if label > 0 else 'background'\n",
    "            label_text = f\"{class_name}: {score:.2f}\"\n",
    "            cv2.putText(or_im_rgb, label_text, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "        \n",
    "        plt.imshow(or_im_rgb)\n",
    "        plt.title(f\"Imagem #{idx + 1} - {len(boxes)} detec√ß√µes\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualiza resultados\n",
    "visualizar_inferencia_ssd(results, n_ims=15, rows=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
