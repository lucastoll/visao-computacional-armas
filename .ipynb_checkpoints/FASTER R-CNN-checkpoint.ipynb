{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 6244,
     "status": "ok",
     "timestamp": 1763253439528,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "qEsQBCPL4j6f"
   },
   "source": [
    "<div style='background-color: #f0f8ff; border: 3px solid Blue;'>\n",
    "    <font size=\"+1\" color=\"Blue\">\n",
    "        <b>üöÄ Notebook de Treinamento Faster R-CNN para Detec√ß√£o de Armas</b>\n",
    "    </font>\n",
    "</div>\n",
    "<div style='background-color: #fff7f7; border: 2px solid Green;'>\n",
    "    <font size=\"+1\" color=\"Green\">\n",
    "        <b>‚úÖ Dataset configurado: dataset_final_coco</b>\n",
    "    </font>\n",
    "</div>\n",
    "<div style='background-color: #fffacd; border: 2px solid Orange;'>\n",
    "    <font size=\"+1\" color=\"Orange\">\n",
    "        <b>üì¶ Modelo: Faster R-CNN com ResNet-50 FPN</b>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102310,
     "status": "ok",
     "timestamp": 1763253541847,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "rqNnp8_Ov8zA",
    "outputId": "4ba8a921-34e7-47bc-de44-affe02a0834d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Instalando depend√™ncias...\n",
      "‚úÖ pycocotools instalado com sucesso!\n",
      "‚úÖ albumentations instalado com sucesso!\n",
      "‚úÖ seaborn instalado com sucesso!\n",
      "‚úÖ albumentations importado com sucesso! Vers√£o: 2.0.8\n",
      "‚úÖ seaborn importado com sucesso! Vers√£o: 0.13.2\n",
      "üîç Verificando GPU...\n",
      "‚úÖ GPU detectada: NVIDIA GeForce GTX 1060 6GB\n",
      "‚úÖ CUDA Version: 12.1\n",
      "\n",
      "üìÅ Diret√≥rio base: D:\\Desktop\\Projetos\\visao\n",
      "üìÅ Dataset: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\n",
      "‚úÖ Dataset encontrado!\n",
      "üìä Imagens de treino: 15015\n",
      "üìä Imagens de valida√ß√£o: 4290\n",
      "üìä Imagens de teste: 2146\n",
      "‚úÖ Anota√ß√µes de treino encontradas: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\\coco_annotations_train.json\n",
      "‚úÖ Anota√ß√µes de valida√ß√£o encontradas: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\\coco_annotations_val.json\n",
      "‚úÖ Anota√ß√µes de teste encontradas: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\\coco_annotations_test.json\n"
     ]
    }
   ],
   "source": [
    "# Instala depend√™ncias necess√°rias\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Instala um pacote usando pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--upgrade\"])\n",
    "        print(f\"‚úÖ {package} instalado com sucesso!\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Erro ao instalar {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Instala pacotes necess√°rios\n",
    "print(\"üì¶ Instalando depend√™ncias...\")\n",
    "install_package(\"pycocotools\")\n",
    "install_package(\"albumentations\")\n",
    "install_package(\"seaborn\")\n",
    "\n",
    "# Verifica se os pacotes foram instalados corretamente\n",
    "try:\n",
    "    import albumentations as A\n",
    "    print(f\"‚úÖ albumentations importado com sucesso! Vers√£o: {A.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar albumentations: {e}\")\n",
    "    print(\"üí° Tente reiniciar o kernel ap√≥s a instala√ß√£o!\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    print(f\"‚úÖ seaborn importado com sucesso! Vers√£o: {sns.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar seaborn: {e}\")\n",
    "    print(\"üí° Tente reiniciar o kernel ap√≥s a instala√ß√£o!\")\n",
    "    raise\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "# Verifica GPU\n",
    "print(\"üîç Verificando GPU...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GPU n√£o dispon√≠vel - usando CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Define o diret√≥rio base e caminhos do dataset\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset_final_coco\")\n",
    "root_dir = DATASET_DIR\n",
    "\n",
    "print(f\"\\nüìÅ Diret√≥rio base: {BASE_DIR}\")\n",
    "print(f\"üìÅ Dataset: {DATASET_DIR}\")\n",
    "\n",
    "# Verifica se o dataset existe\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    print(\"‚úÖ Dataset encontrado!\")\n",
    "    \n",
    "    # Verifica estrutura do dataset\n",
    "    train_images_path = os.path.join(DATASET_DIR, \"train\", \"images\")\n",
    "    val_images_path = os.path.join(DATASET_DIR, \"val\", \"images\")\n",
    "    test_images_path = os.path.join(DATASET_DIR, \"test\", \"images\")\n",
    "    \n",
    "    train_images = len([f for f in os.listdir(train_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(train_images_path) else 0\n",
    "    val_images = len([f for f in os.listdir(val_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(val_images_path) else 0\n",
    "    test_images = len([f for f in os.listdir(test_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(test_images_path) else 0\n",
    "    \n",
    "    print(f\"üìä Imagens de treino: {train_images}\")\n",
    "    print(f\"üìä Imagens de valida√ß√£o: {val_images}\")\n",
    "    print(f\"üìä Imagens de teste: {test_images}\")\n",
    "    \n",
    "    # Verifica arquivos de anota√ß√£o COCO\n",
    "    train_ann = os.path.join(DATASET_DIR, \"coco_annotations_train.json\")\n",
    "    val_ann = os.path.join(DATASET_DIR, \"coco_annotations_val.json\")\n",
    "    test_ann = os.path.join(DATASET_DIR, \"coco_annotations_test.json\")\n",
    "    \n",
    "    if os.path.exists(train_ann):\n",
    "        print(f\"‚úÖ Anota√ß√µes de treino encontradas: {train_ann}\")\n",
    "    if os.path.exists(val_ann):\n",
    "        print(f\"‚úÖ Anota√ß√µes de valida√ß√£o encontradas: {val_ann}\")\n",
    "    if os.path.exists(test_ann):\n",
    "        print(f\"‚úÖ Anota√ß√µes de teste encontradas: {test_ann}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o encontrado! Verifique o caminho.\")\n",
    "    print(f\"   Caminho esperado: {DATASET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1763253543383,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "fkLOOU-34F8z"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ------------------------------\n",
    "# TRANSFORMS SEM AUGMENTATION\n",
    "# Apenas pr√©-processamento essencial: resize, normaliza√ß√£o e convers√£o para tensor\n",
    "# ------------------------------\n",
    "\n",
    "def get_train_transforms():\n",
    "    \"\"\"\n",
    "    Transforma√ß√µes para treino - SEM augmentation.\n",
    "    Apenas pr√©-processamento necess√°rio.\n",
    "    \"\"\"\n",
    "    return A.Compose(\n",
    "        [\n",
    "            # Redimensionar para tamanho fixo (necess√°rio)\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            \n",
    "            # Normalizar (necess√°rio para modelos pr√©-treinados)\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),  # M√©dias ImageNet\n",
    "                std=(0.229, 0.224, 0.225),   # Desvios ImageNet\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            \n",
    "            # Converter para tensor PyTorch (necess√°rio)\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(\n",
    "            format=\"pascal_voc\",\n",
    "            label_fields=[\"labels\"],\n",
    "            min_visibility=0.0  # N√£o filtrar caixas\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_eval_transforms():\n",
    "    \"\"\"\n",
    "    Transforma√ß√µes para valida√ß√£o/teste - SEM augmentation.\n",
    "    Apenas pr√©-processamento necess√°rio.\n",
    "    \"\"\"\n",
    "    return A.Compose(\n",
    "        [\n",
    "            # Redimensionar para tamanho fixo (necess√°rio)\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            \n",
    "            # Normalizar (necess√°rio para modelos pr√©-treinados)\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),  # M√©dias ImageNet\n",
    "                std=(0.229, 0.224, 0.225),   # Desvios ImageNet\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            \n",
    "            # Converter para tensor PyTorch (necess√°rio)\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(\n",
    "            format=\"pascal_voc\",\n",
    "            label_fields=[\"labels\"],\n",
    "            min_visibility=0.0  # N√£o filtrar caixas\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1763253543398,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "pyREej1016ZH"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "class CocoAlbumentationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, ann_file, transforms=None):\n",
    "        import json\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.images = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "\n",
    "        # agrupar anota√ß√µes por imagem\n",
    "        self.annotations = {}\n",
    "        for ann in data[\"annotations\"]:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id not in self.annotations:\n",
    "                self.annotations[img_id] = []\n",
    "            self.annotations[img_id].append(ann)\n",
    "\n",
    "        self.ids = list(self.images.keys())\n",
    "        \n",
    "        # Verifica√ß√£o de anota√ß√µes\n",
    "        self._verify_annotations()\n",
    "    \n",
    "    def _verify_annotations(self):\n",
    "        \"\"\"Verifica se as anota√ß√µes est√£o corretas\"\"\"\n",
    "        total_images = len(self.images)\n",
    "        images_with_anns = len(self.annotations)\n",
    "        total_anns = sum(len(anns) for anns in self.annotations.values())\n",
    "        \n",
    "        # Verificar anota√ß√µes inv√°lidas\n",
    "        invalid_anns = 0\n",
    "        for img_id, anns in self.annotations.items():\n",
    "            for ann in anns:\n",
    "                x, y, w, h = ann[\"bbox\"]\n",
    "                if w <= 0 or h <= 0 or x < 0 or y < 0:\n",
    "                    invalid_anns += 1\n",
    "        \n",
    "        print(f\"   ‚úÖ Verifica√ß√£o de anota√ß√µes:\")\n",
    "        print(f\"      üìä Imagens: {total_images}\")\n",
    "        print(f\"      üìä Imagens com anota√ß√µes: {images_with_anns}\")\n",
    "        print(f\"      üìä Total de anota√ß√µes: {total_anns}\")\n",
    "        if invalid_anns > 0:\n",
    "            print(f\"      ‚ö†Ô∏è  Anota√ß√µes inv√°lidas: {invalid_anns}\")\n",
    "        else:\n",
    "            print(f\"      ‚úÖ Todas as anota√ß√µes s√£o v√°lidas\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        info = self.images[img_id]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, info[\"file_name\"])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        annots = self.annotations.get(img_id, [])\n",
    "\n",
    "        # se n√£o tem boxes ‚Üí pula imagem\n",
    "        if len(annots) == 0:\n",
    "            return None\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for ann in annots:\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        original_box_count = len(boxes)\n",
    "        \n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(\n",
    "                image=image,\n",
    "                bboxes=boxes,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            image = transformed[\"image\"]\n",
    "            boxes = transformed[\"bboxes\"]\n",
    "            labels = transformed[\"labels\"]\n",
    "            \n",
    "            # Log se muitas caixas foram perdidas\n",
    "            if len(boxes) < original_box_count * 0.5:\n",
    "                print(f\"      ‚ö†Ô∏è  Aten√ß√£o: {original_box_count - len(boxes)}/{original_box_count} caixas perdidas na transforma√ß√£o\")\n",
    "\n",
    "        # üö® Prote√ß√£o contra augmentations removerem TODAS as caixas\n",
    "        if len(boxes) == 0:\n",
    "            return None\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([img_id], dtype=torch.int64)\n",
    "        }\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1763253543410,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "ZjJplR4N2E8V"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return tuple(zip(*batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1763253543690,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "IedNChtP4Fvz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Criando dataset de treino...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CocoAlbumentationsDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Criar datasets completos (com verifica√ß√£o de anota√ß√µes)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müì¶ Criando dataset de treino...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m train_dataset_full = \u001b[43mCocoAlbumentationsDataset\u001b[49m(\n\u001b[32m     10\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/train/images\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/coco_annotations_train.json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     transforms=get_train_transforms()\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì¶ Criando dataset de valida√ß√£o...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m val_dataset_full = CocoAlbumentationsDataset(\n\u001b[32m     17\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/val/images\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/coco_annotations_val.json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     transforms=get_eval_transforms()\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'CocoAlbumentationsDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# REDU√á√ÉO DRASTICA DO DATASET PARA ECONOMIZAR MEM√ìRIA\n",
    "# ================================================================\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "# Criar datasets completos (com verifica√ß√£o de anota√ß√µes)\n",
    "print(\"üì¶ Criando dataset de treino...\")\n",
    "train_dataset_full = CocoAlbumentationsDataset(\n",
    "    f\"{root_dir}/train/images\",\n",
    "    f\"{root_dir}/coco_annotations_train.json\",\n",
    "    transforms=get_train_transforms()\n",
    ")\n",
    "\n",
    "print(\"\\nüì¶ Criando dataset de valida√ß√£o...\")\n",
    "val_dataset_full = CocoAlbumentationsDataset(\n",
    "    f\"{root_dir}/val/images\",\n",
    "    f\"{root_dir}/coco_annotations_val.json\",\n",
    "    transforms=get_eval_transforms()\n",
    ")\n",
    "\n",
    "test_dataset = CocoAlbumentationsDataset(\n",
    "    f\"{root_dir}/test/images\",\n",
    "    f\"{root_dir}/coco_annotations_test.json\",\n",
    "    transforms=get_eval_transforms()\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURA√á√ÉO: Usar mais dados para melhor aprendizado\n",
    "# ================================================================\n",
    "TRAIN_SUBSET_PERCENT = 0.10  # Usar 50% dos dados de treino (aumentado de 5%)\n",
    "VAL_SUBSET_PERCENT = 0.05    # Usar 50% dos dados de valida√ß√£o (aumentado de 10%)\n",
    "BATCH_SIZE = 12              # Mantido em 12\n",
    "\n",
    "# Criar subsets reduzidos\n",
    "print(f\"üìä Dataset completo de treino: {len(train_dataset_full)} imagens\")\n",
    "print(f\"üìä Dataset completo de valida√ß√£o: {len(val_dataset_full)} imagens\")\n",
    "\n",
    "# Selecionar √≠ndices aleat√≥rios para o subset\n",
    "train_size = int(len(train_dataset_full) * TRAIN_SUBSET_PERCENT)\n",
    "val_size = int(len(val_dataset_full) * VAL_SUBSET_PERCENT)\n",
    "\n",
    "# Fixar seed para reprodutibilidade\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_indices = random.sample(range(len(train_dataset_full)), train_size)\n",
    "val_indices = random.sample(range(len(val_dataset_full)), val_size)\n",
    "\n",
    "# Criar subsets\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "val_dataset = Subset(val_dataset_full, val_indices)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset reduzido:\")\n",
    "print(f\"   üìä Treino: {len(train_dataset)} imagens ({TRAIN_SUBSET_PERCENT*100:.0f}% do original)\")\n",
    "print(f\"   üìä Valida√ß√£o: {len(val_dataset)} imagens ({VAL_SUBSET_PERCENT*100:.0f}% do original)\")\n",
    "print(f\"   üìä Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Criar DataLoaders com batch_size reduzido\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Calcular n√∫mero de batches\n",
    "num_train_batches = len(train_loader)\n",
    "num_val_batches = len(val_loader)\n",
    "\n",
    "print(f\"\\nüìä Batches por √©poca:\")\n",
    "print(f\"   üéØ Treino: ~{num_train_batches} batches\")\n",
    "print(f\"   üéØ Valida√ß√£o: ~{num_val_batches} batches\")\n",
    "print(f\"\\nüí° Redu√ß√£o de ~{938 - num_train_batches} batches por √©poca!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7269,
     "status": "ok",
     "timestamp": 1763253550961,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "_vlvjq1XweXt",
    "outputId": "38a3a092-3c89-49b3-824c-430e54620840"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "num_classes = 2  # background + gun\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=\"DEFAULT\",\n",
    "    box_score_thresh=0.5,\n",
    ")\n",
    "\n",
    "# substituir head com dropout\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "    in_features, num_classes\n",
    ")\n",
    "\n",
    "# aplicar dropout manualmente\n",
    "model.roi_heads.box_predictor.cls_score = nn.Sequential(\n",
    "    nn.Dropout(0.05),\n",
    "    nn.Linear(in_features, num_classes)\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# ================================================================\n",
    "# OTMIZADOR - ESCOLHA UMA OP√á√ÉO:\n",
    "# ================================================================\n",
    "\n",
    "# OP√á√ÉO 1: M√çNIMO (s√≥ learning rate)\n",
    "# Mais simples, mas pode ser mais lento e inst√°vel\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# OP√á√ÉO 2: PADR√ÉO PyTorch (expl√≠cito)\n",
    "# momentum=0 e weight_decay=0 s√£o os padr√µes do PyTorch\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0, weight_decay=0)\n",
    "\n",
    "# OP√á√ÉO 3: RECOMENDADO para detec√ß√£o de objetos\n",
    "# Usa momentum e weight_decay (valores comuns em YOLO, Faster R-CNN, etc.)\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=0.001,\n",
    "#     momentum=0.937,      # Acelera converg√™ncia\n",
    "#     weight_decay=0.0005  # Reduz overfitting\n",
    "# )\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=0.01,\n",
    "    total_iters=10  # 100 √©pocas\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1763253550966,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "vTcwm5wOw5X2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "save_dir = \"runs/fasterrcnn/train1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"lr\": [],\n",
    "    \"epoch\": [],\n",
    "    \"map50\": [],\n",
    "    \"map5095\": []\n",
    "}\n",
    "\n",
    "with open(f\"{save_dir}/history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# FUN√á√ïES DE CHECKPOINT PARA CONTINUAR TREINAMENTO\n",
    "# ================================================================\n",
    "def save_checkpoint(model, optimizer, lr_scheduler, epoch, best_loss, counter, history, save_dir):\n",
    "    \"\"\"Salva checkpoint completo do treinamento\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'counter': counter,\n",
    "        'history': history\n",
    "    }\n",
    "    checkpoint_path = f\"{save_dir}/checkpoint_last.pth\"\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"üíæ Checkpoint salvo: {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, lr_scheduler, save_dir):\n",
    "    \"\"\"Carrega checkpoint se existir\"\"\"\n",
    "    checkpoint_path = f\"{save_dir}/checkpoint_last.pth\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"üìÇ Carregando checkpoint: {checkpoint_path}\")\n",
    "        device = next(model.parameters()).device  # Obter device do modelo\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1  # Continuar da pr√≥xima √©poca\n",
    "        best_loss = checkpoint['best_loss']\n",
    "        counter = checkpoint['counter']\n",
    "        history = checkpoint['history']\n",
    "        \n",
    "        print(f\"‚úÖ Checkpoint carregado!\")\n",
    "        print(f\"   üìç Continuando da √©poca {start_epoch}\")\n",
    "        print(f\"   üìä Melhor loss at√© agora: {best_loss:.4f}\")\n",
    "        print(f\"   üìà √âpocas j√° treinadas: {len(history['epoch'])}\")\n",
    "        \n",
    "        return start_epoch, best_loss, counter, history\n",
    "    else:\n",
    "        print(\"üÜï Nenhum checkpoint encontrado. Iniciando treinamento do zero.\")\n",
    "        return 0, float(\"inf\"), 0, {\n",
    "            \"train_loss\": [],\n",
    "            \"lr\": [],\n",
    "            \"epoch\": [],\n",
    "            \"map50\": [],\n",
    "            \"map5095\": []\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1763253552091,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "enXUlgmTw8-F"
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# M√âTRICAS COCO COMPLETAS\n",
    "# ================================================================\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "def evaluate_coco(model, dataset, ann_path, device=\"cuda\", score_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Avalia modelo usando m√©tricas COCO.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de detec√ß√£o\n",
    "        dataset: Dataset de valida√ß√£o\n",
    "        ann_path: Caminho para anota√ß√µes COCO\n",
    "        device: Device (cuda/cpu)\n",
    "        score_threshold: Score m√≠nimo para incluir predi√ß√£o (padr√£o: 0.3)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    coco_gt = COCO(ann_path)\n",
    "    \n",
    "    # Garantir que o dataset tenha a chave 'info' necess√°ria para loadRes\n",
    "    if 'info' not in coco_gt.dataset:\n",
    "        coco_gt.dataset['info'] = {\n",
    "            \"description\": \"COCO Dataset\",\n",
    "            \"version\": \"1.0\",\n",
    "            \"year\": 2024\n",
    "        }\n",
    "    \n",
    "    results = []\n",
    "    total_preds = 0\n",
    "    filtered_preds = 0\n",
    "\n",
    "    for img, target in dataset:\n",
    "        img_tensor = img.to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)[0]\n",
    "\n",
    "        boxes = output[\"boxes\"].cpu().numpy()\n",
    "        scores = output[\"scores\"].cpu().numpy()\n",
    "        labels = output[\"labels\"].cpu().numpy()\n",
    "\n",
    "        image_id = int(target[\"image_id\"].item())\n",
    "\n",
    "        # Filtrar predi√ß√µes por score m√≠nimo\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            total_preds += 1\n",
    "            # Apenas incluir predi√ß√µes com score acima do threshold\n",
    "            if score >= score_threshold:\n",
    "                filtered_preds += 1\n",
    "                x1, y1, x2, y2 = box.tolist()\n",
    "                results.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": 1,\n",
    "                    \"bbox\": [x1, y1, x2 - x1, y2 - y1],\n",
    "                    \"score\": float(score)\n",
    "                })\n",
    "    \n",
    "    print(f\"   üìä Predi√ß√µes: {total_preds} total, {filtered_preds} ap√≥s filtro (score >= {score_threshold})\")\n",
    "\n",
    "    # Verificar se h√° resultados\n",
    "    if len(results) == 0:\n",
    "        print(\"‚ö†Ô∏è  Nenhum resultado para avaliar!\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Carregar resultados\n",
    "    try:\n",
    "        coco_dt = coco_gt.loadRes(results)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao carregar resultados: {e}\")\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    # mAP50 = COCO metric 1\n",
    "    # mAP50-95 = COCO metric 0\n",
    "    map50 = coco_eval.stats[1]\n",
    "    map5095 = coco_eval.stats[0]\n",
    "\n",
    "    return map50, map5095\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FUNCTION ‚Äî CONFUSION MATRIX\n",
    "# ================================================================\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path):\n",
    "    labels = [\"background\", \"Gun\"]\n",
    "    cm = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t][p] += 1\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FUNCTION ‚Äî PRECISION-RECALL CURVE\n",
    "# ================================================================\n",
    "def plot_pr_curve(precisions, recalls, save_path):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.grid()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FUNCTION ‚Äî F1 CURVE\n",
    "# ================================================================\n",
    "def plot_f1_curve(precisions, recalls, save_path):\n",
    "    f1 = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(recalls, f1)\n",
    "    plt.title(\"F1 Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"F1-score\")\n",
    "    plt.grid()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "oL4alx3NwhcS",
    "outputId": "4132dbfc-9e8d-45ec-e8b6-46538f0e7e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Carregando checkpoint: runs/fasterrcnn/train1/checkpoint_last.pth\n",
      "‚úÖ Checkpoint carregado!\n",
      "   üìç Continuando da √©poca 4\n",
      "   üìä Melhor loss at√© agora: 15.4136\n",
      "   üìà √âpocas j√° treinadas: 4\n",
      "\n",
      "üöÄ Iniciando treinamento: √©pocas 4 a 9\n",
      "\n",
      "[Epoch 4] Batch 0: 12 imagens\n",
      "  Loss do batch: 0.1076\n",
      "[Epoch 4] Batch 1: 12 imagens\n",
      "  Loss do batch: 0.0718\n",
      "[Epoch 4] Batch 2: 12 imagens\n",
      "  Loss do batch: 0.0706\n",
      "[Epoch 4] Batch 3: 12 imagens\n",
      "  Loss do batch: 0.1117\n",
      "[Epoch 4] Batch 4: 12 imagens\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m targets = [{k: v.cuda() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t.items()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m loss_dict = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m losses = \u001b[38;5;28msum\u001b[39m(loss_dict.values())\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# outra linha de LOG opcional:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:101\u001b[39m, in \u001b[36mGeneralizedRCNN.forward\u001b[39m\u001b[34m(self, images, targets)\u001b[39m\n\u001b[32m     94\u001b[39m             degen_bb: List[\u001b[38;5;28mfloat\u001b[39m] = boxes[bb_idx].tolist()\n\u001b[32m     95\u001b[39m             torch._assert(\n\u001b[32m     96\u001b[39m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     97\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mAll bounding boxes should have positive height and width.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     99\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch.Tensor):\n\u001b[32m    103\u001b[39m     features = OrderedDict([(\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m, features)])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\detection\\backbone_utils.py:57\u001b[39m, in \u001b[36mBackboneWithFPN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.fpn(x)\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:69\u001b[39m, in \u001b[36mIntermediateLayerGetter.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     67\u001b[39m out = OrderedDict()\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items():\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     x = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_layers:\n\u001b[32m     71\u001b[39m         out_name = \u001b[38;5;28mself\u001b[39m.return_layers[name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\resnet.py:147\u001b[39m, in \u001b[36mBottleneck.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    144\u001b[39m identity = x\n\u001b[32m    146\u001b[39m out = \u001b[38;5;28mself\u001b[39m.conv1(x)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m out = \u001b[38;5;28mself\u001b[39m.relu(out)\n\u001b[32m    150\u001b[39m out = \u001b[38;5;28mself\u001b[39m.conv2(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================================================================\n",
    "# INICIALIZA√á√ÉO E CARREGAMENTO DE CHECKPOINT\n",
    "# ================================================================\n",
    "patience = 20\n",
    "start_epoch, best_loss, counter, history = load_checkpoint(model, optimizer, lr_scheduler, save_dir)\n",
    "\n",
    "# Se n√£o carregou checkpoint, inicializa hist√≥rico vazio\n",
    "if len(history.get('epoch', [])) == 0:\n",
    "    with open(f\"{save_dir}/history.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "# Definir n√∫mero total de √©pocas desejadas\n",
    "num_epochs = 4  # Ajuste este valor conforme necess√°rio\n",
    "\n",
    "# Verificar se ainda h√° √©pocas para treinar\n",
    "if start_epoch >= num_epochs:\n",
    "    print(f\"‚ö†Ô∏è  Treinamento j√° completo! √öltima √©poca treinada: {start_epoch-1}, Total desejado: {num_epochs}\")\n",
    "    print(\"   Para continuar, aumente o valor de 'num_epochs'\")\n",
    "else:\n",
    "    print(f\"\\nüöÄ Iniciando treinamento: √©pocas {start_epoch} a {num_epochs-1}\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "\n",
    "        # üîç LOG DO BATCH\n",
    "        print(f\"[Epoch {epoch}] Batch {batch_idx}: {len(imgs)} imagens\")\n",
    "\n",
    "        # detectar erros comuns\n",
    "        for i, t in enumerate(targets):\n",
    "            if t[\"boxes\"].shape[0] == 0:\n",
    "                print(f\"  ‚ö†Ô∏è  Aten√ß√£o: imagem {i} no batch {batch_idx} est√° com boxes vazios!\")\n",
    "\n",
    "        # GPU\n",
    "        imgs = [img.cuda() for img in imgs]\n",
    "        targets = [{k: v.cuda() for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # forward\n",
    "        loss_dict = model(imgs, targets)\n",
    "        losses = sum(loss_dict.values())\n",
    "\n",
    "        # outra linha de LOG opcional:\n",
    "        print(f\"  Loss do batch: {losses.item():.4f}\")\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += losses.item()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # =======================================================\n",
    "    # AVALIA√á√ÉO COCO EM VAL (com filtro de score)\n",
    "    # =======================================================\n",
    "    map50, map5095 = evaluate_coco(\n",
    "        model,\n",
    "        val_dataset,\n",
    "        f\"{root_dir}/coco_annotations_val.json\",\n",
    "        score_threshold=0.3  # Filtrar predi√ß√µes com score < 0.3\n",
    "    )\n",
    "\n",
    "    print(f\"   mAP50={map50:.4f} | mAP50-95={map5095:.4f}\")\n",
    "\n",
    "    # =======================================================\n",
    "    # Salvar hist√≥rico\n",
    "    # =======================================================\n",
    "    history[\"train_loss\"].append(total_loss)\n",
    "    history[\"map50\"].append(map50)\n",
    "    history[\"map5095\"].append(map5095)\n",
    "    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "    history[\"epoch\"].append(epoch)\n",
    "\n",
    "    with open(f\"{save_dir}/history.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    # =======================================================\n",
    "    # SALVAR CHECKPOINT AP√ìS CADA √âPOCA\n",
    "    # =======================================================\n",
    "    save_checkpoint(model, optimizer, lr_scheduler, epoch, best_loss, counter, history, save_dir)\n",
    "\n",
    "    # =======================================================\n",
    "    # EARLY STOPPING\n",
    "    # =======================================================\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f\"{save_dir}/best_model.pth\")\n",
    "        print(f\"   ‚úÖ Novo melhor modelo salvo! (Loss: {best_loss:.4f})\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"EARLY STOPPING\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# GERAR GR√ÅFICOS AP√ìS O TREINAMENTO\n",
    "# =======================================================\n",
    "\n",
    "# Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"train_loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.savefig(f\"{save_dir}/losses.png\")\n",
    "plt.close()\n",
    "\n",
    "# mAP plot\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"map50\"], label=\"mAP50\")\n",
    "plt.plot(history[\"epoch\"], history[\"map5095\"], label=\"mAP50-95\")\n",
    "plt.legend()\n",
    "plt.title(\"mAP Curve\")\n",
    "plt.savefig(f\"{save_dir}/map_curve.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TboIwUKrxDna"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m all_labels = []\n\u001b[32m      7\u001b[39m all_preds = []\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mmodel\u001b[49m.eval()\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img, target \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[32m     11\u001b[39m     img_tensor = img.cuda().unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# FINAL EVALUATION FOR PR + F1 + CONFUSION MATRIX\n",
    "# ================================================================\n",
    "\n",
    "all_scores = []\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()\n",
    "for img, target in val_dataset:\n",
    "    img_tensor = img.cuda().unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(img_tensor)[0]\n",
    "\n",
    "    scores = out[\"scores\"].cpu().numpy()\n",
    "    labels_pred = out[\"labels\"].cpu().numpy()\n",
    "    labels_true = target[\"labels\"].numpy()\n",
    "\n",
    "    # armazenar\n",
    "    all_scores.extend(scores)\n",
    "    all_preds.extend(labels_pred)\n",
    "    all_labels.extend(labels_true)\n",
    "\n",
    "\n",
    "# ORDENAR POR SCORE PARA PR CURVE\n",
    "order = np.argsort(-np.array(all_scores))\n",
    "preds = np.array(all_preds)[order]\n",
    "labels = np.array(all_labels)[order]\n",
    "\n",
    "tp = (preds == labels)\n",
    "fp = (preds != labels)\n",
    "fn = (labels != preds)\n",
    "\n",
    "precision = np.cumsum(tp) / (np.cumsum(tp + fp) + 1e-6)\n",
    "recall = np.cumsum(tp) / (len(labels) + 1e-6)\n",
    "\n",
    "plot_pr_curve(precision, recall, f\"{save_dir}/pr_curve.png\")\n",
    "plot_f1_curve(precision, recall, f\"{save_dir}/f1_curve.png\")\n",
    "plot_confusion_matrix(all_labels, all_preds, f\"{save_dir}/confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xweWGwbbxG8N"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img1 = Image.open(f\"{save_dir}/losses.png\")\n",
    "img2 = Image.open(f\"{save_dir}/map_curve.png\")\n",
    "img3 = Image.open(f\"{save_dir}/pr_curve.png\")\n",
    "img4 = Image.open(f\"{save_dir}/f1_curve.png\")\n",
    "\n",
    "width = max(img1.width, img2.width)\n",
    "height = img1.height + img2.height + img3.height + img4.height\n",
    "\n",
    "results = Image.new(\"RGB\", (width, height), \"white\")\n",
    "\n",
    "y = 0\n",
    "for img in [img1, img2, img3, img4]:\n",
    "    results.paste(img, (0, y))\n",
    "    y += img.height\n",
    "\n",
    "results.save(f\"{save_dir}/results.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WPlBbJh3wkSr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Carregando modelo: runs/fasterrcnn/train1/best_model.pth\n",
      "‚úÖ Modelo carregado com sucesso!\n",
      "\n",
      "============================================================\n",
      "üîç AVALIANDO MODELO NO CONJUNTO DE TESTE\n",
      "============================================================\n",
      "\n",
      "üìä Calculando m√©tricas COCO...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# ================================================================\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 1. CALCULAR M√âTRICAS COCO (mAP50 e mAP50-95)\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# ================================================================\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìä Calculando m√©tricas COCO...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     34\u001b[39m map50, map5095 = evaluate_coco(\n\u001b[32m     35\u001b[39m     model,\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[43mtest_dataset\u001b[49m,\n\u001b[32m     37\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/coco_annotations_test.json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     39\u001b[39m     score_threshold=\u001b[32m0.3\u001b[39m\n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ M√©tricas COCO:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   üéØ mAP@0.5: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmap50\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmap50*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# AVALIA√á√ÉO COMPLETA DO MELHOR MODELO NO CONJUNTO DE TESTE\n",
    "# ================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "# Carregar o melhor modelo salvo durante o treinamento\n",
    "model_path = f\"{save_dir}/best_model.pth\"\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"üìÇ Carregando modelo: {model_path}\")\n",
    "    device = next(model.parameters()).device\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=False))\n",
    "    print(\"‚úÖ Modelo carregado com sucesso!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Arquivo n√£o encontrado: {model_path}\")\n",
    "    print(\"   Verifique se o treinamento foi executado e salvou o modelo.\")\n",
    "    raise FileNotFoundError(f\"Modelo n√£o encontrado: {model_path}\")\n",
    "\n",
    "model.eval()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç AVALIANDO MODELO NO CONJUNTO DE TESTE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ================================================================\n",
    "# 1. CALCULAR M√âTRICAS COCO (mAP50 e mAP50-95)\n",
    "# ================================================================\n",
    "print(\"\\nüìä Calculando m√©tricas COCO...\")\n",
    "map50, map5095 = evaluate_coco(\n",
    "    model,\n",
    "    test_dataset,\n",
    "    f\"{root_dir}/coco_annotations_test.json\",\n",
    "    device=\"cuda\",\n",
    "    score_threshold=0.3\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ M√©tricas COCO:\")\n",
    "print(f\"   üéØ mAP@0.5: {map50:.4f} ({map50*100:.2f}%)\")\n",
    "print(f\"   üéØ mAP@0.5:0.95: {map5095:.4f} ({map5095*100:.2f}%)\")\n",
    "\n",
    "# ================================================================\n",
    "# 2. CALCULAR PRECISION E RECALL DETALHADOS\n",
    "# ================================================================\n",
    "print(\"\\nüìä Calculando Precision e Recall...\")\n",
    "\n",
    "# Coletar todas as predi√ß√µes e ground truths\n",
    "all_pred_boxes = []\n",
    "all_pred_scores = []\n",
    "all_pred_labels = []\n",
    "all_gt_boxes = []\n",
    "all_gt_labels = []\n",
    "\n",
    "score_threshold = 0.3\n",
    "iou_threshold = 0.5\n",
    "\n",
    "for img, target in test_dataset:\n",
    "    img_tensor = img.cuda().unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)[0]\n",
    "    \n",
    "    # Filtrar predi√ß√µes por score\n",
    "    mask = output[\"scores\"].cpu() >= score_threshold\n",
    "    pred_boxes = output[\"boxes\"].cpu()[mask]\n",
    "    pred_scores = output[\"scores\"].cpu()[mask]\n",
    "    pred_labels = output[\"labels\"].cpu()[mask]\n",
    "    \n",
    "    gt_boxes = target[\"boxes\"]\n",
    "    gt_labels = target[\"labels\"]\n",
    "    \n",
    "    all_pred_boxes.append(pred_boxes)\n",
    "    all_pred_scores.append(pred_scores)\n",
    "    all_pred_labels.append(pred_labels)\n",
    "    all_gt_boxes.append(gt_boxes)\n",
    "    all_gt_labels.append(gt_labels)\n",
    "\n",
    "# Calcular IoU entre predi√ß√µes e ground truths\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calcula IoU entre duas caixas no formato [x1, y1, x2, y2]\"\"\"\n",
    "    x1 = torch.max(box1[0], box2[0])\n",
    "    y1 = torch.max(box1[1], box2[1])\n",
    "    x2 = torch.min(box1[2], box2[2])\n",
    "    y2 = torch.min(box1[3], box2[3])\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection = (x2 - x1) * (y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Calcular TP, FP, FN\n",
    "total_tp = 0\n",
    "total_fp = 0\n",
    "total_fn = 0\n",
    "\n",
    "for pred_boxes, pred_labels, gt_boxes, gt_labels in zip(\n",
    "    all_pred_boxes, all_pred_labels, all_gt_boxes, all_gt_labels\n",
    "):\n",
    "    if len(gt_boxes) == 0:\n",
    "        total_fp += len(pred_boxes)\n",
    "        continue\n",
    "    \n",
    "    if len(pred_boxes) == 0:\n",
    "        total_fn += len(gt_boxes)\n",
    "        continue\n",
    "    \n",
    "    # Matriz de IoU\n",
    "    iou_matrix = torch.zeros(len(pred_boxes), len(gt_boxes))\n",
    "    for i, pred_box in enumerate(pred_boxes):\n",
    "        for j, gt_box in enumerate(gt_boxes):\n",
    "            iou_matrix[i, j] = calculate_iou(pred_box, gt_box)\n",
    "    \n",
    "    # Matching: greedy assignment\n",
    "    matched_gt = set()\n",
    "    for i in range(len(pred_boxes)):\n",
    "        best_iou = 0\n",
    "        best_gt_idx = -1\n",
    "        for j in range(len(gt_boxes)):\n",
    "            if j not in matched_gt and iou_matrix[i, j] > best_iou:\n",
    "                best_iou = iou_matrix[i, j]\n",
    "                best_gt_idx = j\n",
    "        \n",
    "        if best_iou >= iou_threshold and pred_labels[i] == gt_labels[best_gt_idx]:\n",
    "            total_tp += 1\n",
    "            matched_gt.add(best_gt_idx)\n",
    "        else:\n",
    "            total_fp += 1\n",
    "    \n",
    "    total_fn += len(gt_boxes) - len(matched_gt)\n",
    "\n",
    "# Calcular m√©tricas\n",
    "precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "print(f\"\\n‚úÖ M√©tricas de Detec√ß√£o:\")\n",
    "print(f\"   üéØ Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"   üéØ Recall: {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"   üéØ F1-Score: {f1_score:.4f} ({f1_score*100:.2f}%)\")\n",
    "print(f\"\\n   üìä Estat√≠sticas:\")\n",
    "print(f\"      ‚úÖ True Positives (TP): {total_tp}\")\n",
    "print(f\"      ‚ùå False Positives (FP): {total_fp}\")\n",
    "print(f\"      ‚ö†Ô∏è  False Negatives (FN): {total_fn}\")\n",
    "\n",
    "# ================================================================\n",
    "# 3. VISUALIZAR RESULTADOS EM ALGUMAS IMAGENS\n",
    "# ================================================================\n",
    "print(\"\\nüñºÔ∏è  Gerando visualiza√ß√µes...\")\n",
    "\n",
    "def visualize_predictions(dataset, model, num_images=6, score_threshold=0.3):\n",
    "    \"\"\"Visualiza predi√ß√µes do modelo em algumas imagens\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Pegar algumas imagens aleat√≥rias\n",
    "    indices = np.random.choice(len(dataset), min(num_images, len(dataset)), replace=False)\n",
    "    \n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx >= len(indices):\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "            \n",
    "        img, target = dataset[indices[idx]]\n",
    "        img_tensor = img.cuda().unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)[0]\n",
    "        \n",
    "        # Converter tensor para numpy para visualiza√ß√£o\n",
    "        img_np = img.cpu().permute(1, 2, 0).numpy()\n",
    "        img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "        \n",
    "        ax.imshow(img_np)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Desenhar ground truth (verde)\n",
    "        for box, label in zip(target[\"boxes\"], target[\"labels\"]):\n",
    "            x1, y1, x2, y2 = box.numpy()\n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                linewidth=2, edgecolor='green', facecolor='none', linestyle='--'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1-5, 'GT', color='green', fontsize=8, weight='bold')\n",
    "        \n",
    "        # Desenhar predi√ß√µes (vermelho)\n",
    "        mask = output[\"scores\"].cpu() >= score_threshold\n",
    "        pred_boxes = output[\"boxes\"].cpu()[mask]\n",
    "        pred_scores = output[\"scores\"].cpu()[mask]\n",
    "        \n",
    "        for box, score in zip(pred_boxes, pred_scores):\n",
    "            x1, y1, x2, y2 = box.numpy()\n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), x2-x1, y2-y1,\n",
    "                linewidth=2, edgecolor='red', facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1, y1-5, f'{score:.2f}', color='red', fontsize=8, weight='bold')\n",
    "        \n",
    "        ax.set_title(f'Imagem {indices[idx]}', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_dir}/test_predictions.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"   ‚úÖ Visualiza√ß√µes salvas em: {save_dir}/test_predictions.png\")\n",
    "\n",
    "# Gerar visualiza√ß√µes\n",
    "visualize_predictions(test_dataset, model, num_images=6, score_threshold=0.3)\n",
    "\n",
    "# ================================================================\n",
    "# 4. RESUMO FINAL\n",
    "# ================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã RESUMO DA AVALIA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"‚úÖ mAP@0.5:        {map50:.4f} ({map50*100:.2f}%)\")\n",
    "print(f\"‚úÖ mAP@0.5:0.95:   {map5095:.4f} ({map5095*100:.2f}%)\")\n",
    "print(f\"‚úÖ Precision:      {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"‚úÖ Recall:         {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"‚úÖ F1-Score:       {f1_score:.4f} ({f1_score*100:.2f}%)\")\n",
    "print(f\"\\nüìä Detec√ß√µes:\")\n",
    "print(f\"   ‚úÖ TP: {total_tp} | ‚ùå FP: {total_fp} | ‚ö†Ô∏è  FN: {total_fn}\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Avalia√ß√£o conclu√≠da!\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKDT1Mx+KuLjaktMfEc1GO",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
