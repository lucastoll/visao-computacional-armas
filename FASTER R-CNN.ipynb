{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 6244,
     "status": "ok",
     "timestamp": 1763253439528,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "qEsQBCPL4j6f"
   },
   "source": [
    "<div style='background-color: #f0f8ff; border: 3px solid Blue;'>\n",
    "    <font size=\"+1\" color=\"Blue\">\n",
    "        <b>üöÄ Notebook de Treinamento Faster R-CNN para Detec√ß√£o de Armas</b>\n",
    "    </font>\n",
    "</div>\n",
    "<div style='background-color: #fff7f7; border: 2px solid Green;'>\n",
    "    <font size=\"+1\" color=\"Green\">\n",
    "        <b>‚úÖ Dataset configurado: dataset_final_coco</b>\n",
    "    </font>\n",
    "</div>\n",
    "<div style='background-color: #fffacd; border: 2px solid Orange;'>\n",
    "    <font size=\"+1\" color=\"Orange\">\n",
    "        <b>üì¶ Modelo: Faster R-CNN com ResNet-50 FPN</b>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102310,
     "status": "ok",
     "timestamp": 1763253541847,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "rqNnp8_Ov8zA",
    "outputId": "4ba8a921-34e7-47bc-de44-affe02a0834d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Instalando depend√™ncias...\n",
      "‚úÖ pycocotools instalado com sucesso!\n",
      "‚úÖ albumentations instalado com sucesso!\n",
      "‚úÖ seaborn instalado com sucesso!\n",
      "‚úÖ albumentations importado com sucesso! Vers√£o: 2.0.8\n",
      "‚úÖ seaborn importado com sucesso! Vers√£o: 0.13.2\n",
      "üîç Verificando GPU...\n",
      "‚úÖ GPU detectada: NVIDIA GeForce GTX 1060 6GB\n",
      "‚úÖ CUDA Version: 12.1\n",
      "\n",
      "üìÅ Diret√≥rio base: D:\\Desktop\\Projetos\\visao\n",
      "üìÅ Dataset: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\n",
      "‚úÖ Dataset encontrado!\n",
      "üìä Imagens de treino: 15015\n",
      "üìä Imagens de valida√ß√£o: 4290\n",
      "üìä Imagens de teste: 2146\n",
      "‚úÖ Anota√ß√µes de treino encontradas: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\\coco_annotations_train.json\n",
      "‚úÖ Anota√ß√µes de valida√ß√£o encontradas: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\\coco_annotations_val.json\n",
      "‚úÖ Anota√ß√µes de teste encontradas: D:\\Desktop\\Projetos\\visao\\dataset_final_coco\\coco_annotations_test.json\n"
     ]
    }
   ],
   "source": [
    "# Instala depend√™ncias necess√°rias\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Instala um pacote usando pip\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--upgrade\"])\n",
    "        print(f\"‚úÖ {package} instalado com sucesso!\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Erro ao instalar {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Instala pacotes necess√°rios\n",
    "print(\"üì¶ Instalando depend√™ncias...\")\n",
    "install_package(\"pycocotools\")\n",
    "install_package(\"albumentations\")\n",
    "install_package(\"seaborn\")\n",
    "\n",
    "# Verifica se os pacotes foram instalados corretamente\n",
    "try:\n",
    "    import albumentations as A\n",
    "    print(f\"‚úÖ albumentations importado com sucesso! Vers√£o: {A.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar albumentations: {e}\")\n",
    "    print(\"üí° Tente reiniciar o kernel ap√≥s a instala√ß√£o!\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    print(f\"‚úÖ seaborn importado com sucesso! Vers√£o: {sns.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå ERRO: N√£o foi poss√≠vel importar seaborn: {e}\")\n",
    "    print(\"üí° Tente reiniciar o kernel ap√≥s a instala√ß√£o!\")\n",
    "    raise\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from pycocotools.coco import COCO\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "# Verifica GPU\n",
    "print(\"üîç Verificando GPU...\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA Version: {torch.version.cuda}\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GPU n√£o dispon√≠vel - usando CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Define o diret√≥rio base e caminhos do dataset\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset_final_coco\")\n",
    "root_dir = DATASET_DIR\n",
    "\n",
    "print(f\"\\nüìÅ Diret√≥rio base: {BASE_DIR}\")\n",
    "print(f\"üìÅ Dataset: {DATASET_DIR}\")\n",
    "\n",
    "# Verifica se o dataset existe\n",
    "if os.path.exists(DATASET_DIR):\n",
    "    print(\"‚úÖ Dataset encontrado!\")\n",
    "    \n",
    "    # Verifica estrutura do dataset\n",
    "    train_images_path = os.path.join(DATASET_DIR, \"train\", \"images\")\n",
    "    val_images_path = os.path.join(DATASET_DIR, \"val\", \"images\")\n",
    "    test_images_path = os.path.join(DATASET_DIR, \"test\", \"images\")\n",
    "    \n",
    "    train_images = len([f for f in os.listdir(train_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(train_images_path) else 0\n",
    "    val_images = len([f for f in os.listdir(val_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(val_images_path) else 0\n",
    "    test_images = len([f for f in os.listdir(test_images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(test_images_path) else 0\n",
    "    \n",
    "    print(f\"üìä Imagens de treino: {train_images}\")\n",
    "    print(f\"üìä Imagens de valida√ß√£o: {val_images}\")\n",
    "    print(f\"üìä Imagens de teste: {test_images}\")\n",
    "    \n",
    "    # Verifica arquivos de anota√ß√£o COCO\n",
    "    train_ann = os.path.join(DATASET_DIR, \"coco_annotations_train.json\")\n",
    "    val_ann = os.path.join(DATASET_DIR, \"coco_annotations_val.json\")\n",
    "    test_ann = os.path.join(DATASET_DIR, \"coco_annotations_test.json\")\n",
    "    \n",
    "    if os.path.exists(train_ann):\n",
    "        print(f\"‚úÖ Anota√ß√µes de treino encontradas: {train_ann}\")\n",
    "    if os.path.exists(val_ann):\n",
    "        print(f\"‚úÖ Anota√ß√µes de valida√ß√£o encontradas: {val_ann}\")\n",
    "    if os.path.exists(test_ann):\n",
    "        print(f\"‚úÖ Anota√ß√µes de teste encontradas: {test_ann}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset n√£o encontrado! Verifique o caminho.\")\n",
    "    print(f\"   Caminho esperado: {DATASET_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1526,
     "status": "ok",
     "timestamp": 1763253543383,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "fkLOOU-34F8z"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ------------------------------\n",
    "# TRAIN TRANSFORMS (fortes)\n",
    "# ------------------------------\n",
    "def get_train_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=0.015,\n",
    "                sat_shift_limit=0.7,\n",
    "                val_shift_limit=0.4,\n",
    "                p=1.0\n",
    "            ),\n",
    "\n",
    "            A.Rotate(limit=30, border_mode=0, p=1.0),\n",
    "\n",
    "            A.Affine(\n",
    "                translate_percent=0.1,\n",
    "                scale=(0.5, 1.5),\n",
    "                shear=(-5, 5),\n",
    "                p=1.0\n",
    "            ),\n",
    "\n",
    "            A.Perspective(scale=(0.0005, 0.0005), p=1.0),\n",
    "\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "\n",
    "            A.RandomCrop(height=416, width=416, p=1.0, pad_if_needed=True),\n",
    "            A.Resize(height=512, width=512, p=1.0),  # Reduzido de 640 para 512\n",
    "\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(\n",
    "            format=\"pascal_voc\",\n",
    "            label_fields=[\"labels\"],\n",
    "            min_visibility=0.2\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# VAL/TEST TRANSFORMS (leves)\n",
    "# ------------------------------\n",
    "def get_eval_transforms():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(512, 512),  # Reduzido de 640 para 512\n",
    "            A.Normalize(\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                max_pixel_value=255.0\n",
    "            ),\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "        bbox_params=A.BboxParams(\n",
    "            format=\"pascal_voc\",\n",
    "            label_fields=[\"labels\"],\n",
    "            min_visibility=0.0\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1763253543398,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "pyREej1016ZH"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "class CocoAlbumentationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, ann_file, transforms=None):\n",
    "        import json\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "        with open(ann_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.images = {img[\"id\"]: img for img in data[\"images\"]}\n",
    "\n",
    "        # agrupar anota√ß√µes por imagem\n",
    "        self.annotations = {}\n",
    "        for ann in data[\"annotations\"]:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id not in self.annotations:\n",
    "                self.annotations[img_id] = []\n",
    "            self.annotations[img_id].append(ann)\n",
    "\n",
    "        self.ids = list(self.images.keys())\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        info = self.images[img_id]\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, info[\"file_name\"])\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        annots = self.annotations.get(img_id, [])\n",
    "\n",
    "        # se n√£o tem boxes ‚Üí pula imagem\n",
    "        if len(annots) == 0:\n",
    "            return None\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "\n",
    "        for ann in annots:\n",
    "            x, y, w, h = ann[\"bbox\"]\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(\n",
    "                image=image,\n",
    "                bboxes=boxes,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            image = transformed[\"image\"]\n",
    "            boxes = transformed[\"bboxes\"]\n",
    "            labels = transformed[\"labels\"]\n",
    "\n",
    "        # üö® Prote√ß√£o contra augmentations removerem TODAS as caixas\n",
    "        if len(boxes) == 0:\n",
    "            return None\n",
    "\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([img_id], dtype=torch.int64)\n",
    "        }\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1763253543410,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "ZjJplR4N2E8V"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return tuple(zip(*batch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1763253543690,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "IedNChtP4Fvz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset completo de treino: 15007 imagens\n",
      "üìä Dataset completo de valida√ß√£o: 4287 imagens\n",
      "\n",
      "‚úÖ Dataset reduzido:\n",
      "   üìä Treino: 750 imagens (5% do original)\n",
      "   üìä Valida√ß√£o: 428 imagens (10% do original)\n",
      "   üìä Batch size: 16\n",
      "\n",
      "üìä Batches por √©poca:\n",
      "   üéØ Treino: ~47 batches\n",
      "   üéØ Valida√ß√£o: ~27 batches\n",
      "\n",
      "üí° Redu√ß√£o de ~891 batches por √©poca!\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# REDU√á√ÉO DRASTICA DO DATASET PARA ECONOMIZAR MEM√ìRIA\n",
    "# ================================================================\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "# Criar datasets completos\n",
    "train_dataset_full = CocoAlbumentationsDataset(\n",
    "    f\"{root_dir}/train/images\",\n",
    "    f\"{root_dir}/coco_annotations_train.json\",\n",
    "    transforms=get_train_transforms()\n",
    ")\n",
    "\n",
    "val_dataset_full = CocoAlbumentationsDataset(\n",
    "    f\"{root_dir}/val/images\",\n",
    "    f\"{root_dir}/coco_annotations_val.json\",\n",
    "    transforms=get_eval_transforms()\n",
    ")\n",
    "\n",
    "test_dataset = CocoAlbumentationsDataset(\n",
    "    f\"{root_dir}/test/images\",\n",
    "    f\"{root_dir}/coco_annotations_test.json\",\n",
    "    transforms=get_eval_transforms()\n",
    ")\n",
    "\n",
    "# ================================================================\n",
    "# CONFIGURA√á√ÉO: Reduzir dataset drasticamente\n",
    "# ================================================================\n",
    "TRAIN_SUBSET_PERCENT = 0.05  # Usar apenas 10% dos dados de treino\n",
    "VAL_SUBSET_PERCENT = 0.10    # Usar apenas 20% dos dados de valida√ß√£o\n",
    "BATCH_SIZE = 16              # Reduzido de 16 para 8\n",
    "\n",
    "# Criar subsets reduzidos\n",
    "print(f\"üìä Dataset completo de treino: {len(train_dataset_full)} imagens\")\n",
    "print(f\"üìä Dataset completo de valida√ß√£o: {len(val_dataset_full)} imagens\")\n",
    "\n",
    "# Selecionar √≠ndices aleat√≥rios para o subset\n",
    "train_size = int(len(train_dataset_full) * TRAIN_SUBSET_PERCENT)\n",
    "val_size = int(len(val_dataset_full) * VAL_SUBSET_PERCENT)\n",
    "\n",
    "# Fixar seed para reprodutibilidade\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "train_indices = random.sample(range(len(train_dataset_full)), train_size)\n",
    "val_indices = random.sample(range(len(val_dataset_full)), val_size)\n",
    "\n",
    "# Criar subsets\n",
    "train_dataset = Subset(train_dataset_full, train_indices)\n",
    "val_dataset = Subset(val_dataset_full, val_indices)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset reduzido:\")\n",
    "print(f\"   üìä Treino: {len(train_dataset)} imagens ({TRAIN_SUBSET_PERCENT*100:.0f}% do original)\")\n",
    "print(f\"   üìä Valida√ß√£o: {len(val_dataset)} imagens ({VAL_SUBSET_PERCENT*100:.0f}% do original)\")\n",
    "print(f\"   üìä Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Criar DataLoaders com batch_size reduzido\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Calcular n√∫mero de batches\n",
    "num_train_batches = len(train_loader)\n",
    "num_val_batches = len(val_loader)\n",
    "\n",
    "print(f\"\\nüìä Batches por √©poca:\")\n",
    "print(f\"   üéØ Treino: ~{num_train_batches} batches\")\n",
    "print(f\"   üéØ Valida√ß√£o: ~{num_val_batches} batches\")\n",
    "print(f\"\\nüí° Redu√ß√£o de ~{938 - num_train_batches} batches por √©poca!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7269,
     "status": "ok",
     "timestamp": 1763253550961,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "_vlvjq1XweXt",
    "outputId": "38a3a092-3c89-49b3-824c-430e54620840"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "num_classes = 2  # background + gun\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
    "    weights=\"DEFAULT\",\n",
    "    box_score_thresh=0.5,\n",
    ")\n",
    "\n",
    "# substituir head com dropout\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(\n",
    "    in_features, num_classes\n",
    ")\n",
    "\n",
    "# aplicar dropout manualmente\n",
    "model.roi_heads.box_predictor.cls_score = nn.Sequential(\n",
    "    nn.Dropout(0.05),\n",
    "    nn.Linear(in_features, num_classes)\n",
    ")\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "# Otimizador\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=1.0,\n",
    "    end_factor=0.01,\n",
    "    total_iters=100  # 100 √©pocas\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1763253550966,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "vTcwm5wOw5X2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "save_dir = \"runs/fasterrcnn/train1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"lr\": [],\n",
    "    \"epoch\": [],\n",
    "    \"map50\": [],\n",
    "    \"map5095\": []\n",
    "}\n",
    "\n",
    "with open(f\"{save_dir}/history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# FUN√á√ïES DE CHECKPOINT PARA CONTINUAR TREINAMENTO\n",
    "# ================================================================\n",
    "def save_checkpoint(model, optimizer, lr_scheduler, epoch, best_loss, counter, history, save_dir):\n",
    "    \"\"\"Salva checkpoint completo do treinamento\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lr_scheduler_state_dict': lr_scheduler.state_dict(),\n",
    "        'best_loss': best_loss,\n",
    "        'counter': counter,\n",
    "        'history': history\n",
    "    }\n",
    "    checkpoint_path = f\"{save_dir}/checkpoint_last.pth\"\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"üíæ Checkpoint salvo: {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, lr_scheduler, save_dir):\n",
    "    \"\"\"Carrega checkpoint se existir\"\"\"\n",
    "    checkpoint_path = f\"{save_dir}/checkpoint_last.pth\"\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"üìÇ Carregando checkpoint: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
    "        \n",
    "        start_epoch = checkpoint['epoch'] + 1  # Continuar da pr√≥xima √©poca\n",
    "        best_loss = checkpoint['best_loss']\n",
    "        counter = checkpoint['counter']\n",
    "        history = checkpoint['history']\n",
    "        \n",
    "        print(f\"‚úÖ Checkpoint carregado!\")\n",
    "        print(f\"   üìç Continuando da √©poca {start_epoch}\")\n",
    "        print(f\"   üìä Melhor loss at√© agora: {best_loss:.4f}\")\n",
    "        print(f\"   üìà √âpocas j√° treinadas: {len(history['epoch'])}\")\n",
    "        \n",
    "        return start_epoch, best_loss, counter, history\n",
    "    else:\n",
    "        print(\"üÜï Nenhum checkpoint encontrado. Iniciando treinamento do zero.\")\n",
    "        return 0, float(\"inf\"), 0, {\n",
    "            \"train_loss\": [],\n",
    "            \"lr\": [],\n",
    "            \"epoch\": [],\n",
    "            \"map50\": [],\n",
    "            \"map5095\": []\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1117,
     "status": "ok",
     "timestamp": 1763253552091,
     "user": {
      "displayName": "Jo√£o Tagliarini",
      "userId": "11097646579698174582"
     },
     "user_tz": 180
    },
    "id": "enXUlgmTw8-F"
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# M√âTRICAS COCO COMPLETAS\n",
    "# ================================================================\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "def evaluate_coco(model, dataset, ann_path, device=\"cuda\"):\n",
    "    model.eval()\n",
    "\n",
    "    coco_gt = COCO(ann_path)\n",
    "    results = []\n",
    "\n",
    "    for img, target in dataset:\n",
    "        img_tensor = img.to(device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)[0]\n",
    "\n",
    "        boxes = output[\"boxes\"].cpu().numpy()\n",
    "        scores = output[\"scores\"].cpu().numpy()\n",
    "        labels = output[\"labels\"].cpu().numpy()\n",
    "\n",
    "        image_id = int(target[\"image_id\"].item())\n",
    "\n",
    "        for box, score, label in zip(boxes, scores, labels):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            results.append({\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": 1,\n",
    "                \"bbox\": [x1, y1, x2 - x1, y2 - y1],\n",
    "                \"score\": float(score)\n",
    "            })\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(results)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, \"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    # mAP50 = COCO metric 1\n",
    "    # mAP50-95 = COCO metric 0\n",
    "    map50 = coco_eval.stats[1]\n",
    "    map5095 = coco_eval.stats[0]\n",
    "\n",
    "    return map50, map5095\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FUNCTION ‚Äî CONFUSION MATRIX\n",
    "# ================================================================\n",
    "def plot_confusion_matrix(y_true, y_pred, save_path):\n",
    "    labels = [\"background\", \"Gun\"]\n",
    "    cm = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t][p] += 1\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FUNCTION ‚Äî PRECISION-RECALL CURVE\n",
    "# ================================================================\n",
    "def plot_pr_curve(precisions, recalls, save_path):\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(recalls, precisions)\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.grid()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# FUNCTION ‚Äî F1 CURVE\n",
    "# ================================================================\n",
    "def plot_f1_curve(precisions, recalls, save_path):\n",
    "    f1 = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(recalls, f1)\n",
    "    plt.title(\"F1 Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"F1-score\")\n",
    "    plt.grid()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "oL4alx3NwhcS",
    "outputId": "4132dbfc-9e8d-45ec-e8b6-46538f0e7e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Batch 0: 15 imagens\n",
      "  Loss do batch: 0.8592\n",
      "[Epoch 0] Batch 1: 14 imagens\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_loss = float(\"inf\")\n",
    "patience = 20\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (imgs, targets) in enumerate(train_loader):\n",
    "\n",
    "        # üîç LOG DO BATCH\n",
    "        print(f\"[Epoch {epoch}] Batch {batch_idx}: {len(imgs)} imagens\")\n",
    "\n",
    "        # detectar erros comuns\n",
    "        for i, t in enumerate(targets):\n",
    "            if t[\"boxes\"].shape[0] == 0:\n",
    "                print(f\"  ‚ö†Ô∏è  Aten√ß√£o: imagem {i} no batch {batch_idx} est√° com boxes vazios!\")\n",
    "\n",
    "        # GPU\n",
    "        imgs = [img.cuda() for img in imgs]\n",
    "        targets = [{k: v.cuda() for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # forward\n",
    "        loss_dict = model(imgs, targets)\n",
    "        losses = sum(loss_dict.values())\n",
    "\n",
    "        # outra linha de LOG opcional:\n",
    "        print(f\"  Loss do batch: {losses.item():.4f}\")\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += losses.item()\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    print(f\"[Epoch {epoch}] Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # =======================================================\n",
    "    # AVALIA√á√ÉO COCO EM VAL\n",
    "    # =======================================================\n",
    "    map50, map5095 = evaluate_coco(\n",
    "        model,\n",
    "        val_dataset,\n",
    "        f\"{root_dir}/coco_annotations_val.json\"\n",
    "    )\n",
    "\n",
    "    print(f\"   mAP50={map50:.4f} | mAP50-95={map5095:.4f}\")\n",
    "\n",
    "    # =======================================================\n",
    "    # Salvar hist√≥rico\n",
    "    # =======================================================\n",
    "    history[\"train_loss\"].append(total_loss)\n",
    "    history[\"map50\"].append(map50)\n",
    "    history[\"map5095\"].append(map5095)\n",
    "    history[\"lr\"].append(optimizer.param_groups[0][\"lr\"])\n",
    "    history[\"epoch\"].append(epoch)\n",
    "\n",
    "    with open(f\"{save_dir}/history.json\", \"w\") as f:\n",
    "        json.dump(history, f, indent=4)\n",
    "\n",
    "    # =======================================================\n",
    "    # EARLY STOPPING\n",
    "    # =======================================================\n",
    "    if total_loss < best_loss:\n",
    "        best_loss = total_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f\"{save_dir}/best_model.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"EARLY STOPPING\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# GERAR GR√ÅFICOS AP√ìS O TREINAMENTO\n",
    "# =======================================================\n",
    "\n",
    "# Loss plot\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"train_loss\"])\n",
    "plt.title(\"Training Loss\")\n",
    "plt.savefig(f\"{save_dir}/losses.png\")\n",
    "plt.close()\n",
    "\n",
    "# mAP plot\n",
    "plt.figure()\n",
    "plt.plot(history[\"epoch\"], history[\"map50\"], label=\"mAP50\")\n",
    "plt.plot(history[\"epoch\"], history[\"map5095\"], label=\"mAP50-95\")\n",
    "plt.legend()\n",
    "plt.title(\"mAP Curve\")\n",
    "plt.savefig(f\"{save_dir}/map_curve.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TboIwUKrxDna"
   },
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# FINAL EVALUATION FOR PR + F1 + CONFUSION MATRIX\n",
    "# ================================================================\n",
    "\n",
    "all_scores = []\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "model.eval()\n",
    "for img, target in val_dataset:\n",
    "    img_tensor = img.cuda().unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(img_tensor)[0]\n",
    "\n",
    "    scores = out[\"scores\"].cpu().numpy()\n",
    "    labels_pred = out[\"labels\"].cpu().numpy()\n",
    "    labels_true = target[\"labels\"].numpy()\n",
    "\n",
    "    # armazenar\n",
    "    all_scores.extend(scores)\n",
    "    all_preds.extend(labels_pred)\n",
    "    all_labels.extend(labels_true)\n",
    "\n",
    "\n",
    "# ORDENAR POR SCORE PARA PR CURVE\n",
    "order = np.argsort(-np.array(all_scores))\n",
    "preds = np.array(all_preds)[order]\n",
    "labels = np.array(all_labels)[order]\n",
    "\n",
    "tp = (preds == labels)\n",
    "fp = (preds != labels)\n",
    "fn = (labels != preds)\n",
    "\n",
    "precision = np.cumsum(tp) / (np.cumsum(tp + fp) + 1e-6)\n",
    "recall = np.cumsum(tp) / (len(labels) + 1e-6)\n",
    "\n",
    "plot_pr_curve(precision, recall, f\"{save_dir}/pr_curve.png\")\n",
    "plot_f1_curve(precision, recall, f\"{save_dir}/f1_curve.png\")\n",
    "plot_confusion_matrix(all_labels, all_preds, f\"{save_dir}/confusion_matrix.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xweWGwbbxG8N"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img1 = Image.open(f\"{save_dir}/losses.png\")\n",
    "img2 = Image.open(f\"{save_dir}/map_curve.png\")\n",
    "img3 = Image.open(f\"{save_dir}/pr_curve.png\")\n",
    "img4 = Image.open(f\"{save_dir}/f1_curve.png\")\n",
    "\n",
    "width = max(img1.width, img2.width)\n",
    "height = img1.height + img2.height + img3.height + img4.height\n",
    "\n",
    "results = Image.new(\"RGB\", (width, height), \"white\")\n",
    "\n",
    "y = 0\n",
    "for img in [img1, img2, img3, img4]:\n",
    "    results.paste(img, (0, y))\n",
    "    y += img.height\n",
    "\n",
    "results.save(f\"{save_dir}/results.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WPlBbJh3wkSr"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"best_fasterrcnn.pth\"))\n",
    "model.eval()\n",
    "\n",
    "results = []\n",
    "\n",
    "for img, target in test_dataset:\n",
    "    img_tensor = img.cuda().unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)[0]\n",
    "\n",
    "    results.append({\n",
    "        \"image_id\": target[\"image_id\"].item(),\n",
    "        \"boxes\": output[\"boxes\"].cpu().tolist(),\n",
    "        \"scores\": output[\"scores\"].cpu().tolist(),\n",
    "        \"labels\": output[\"labels\"].cpu().tolist()\n",
    "    })\n",
    "\n",
    "print(\"Infer√™ncia conclu√≠da!\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNKDT1Mx+KuLjaktMfEc1GO",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
